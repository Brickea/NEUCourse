{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">INFO 6105 Data Science Eng Methods and Tools, Lecture 6 Day 1</div>\n",
    "<div style=\"text-align: right\">Dino Konstantopoulos, 7 October 2019, with material from Thomas Wiecki</div>\n",
    "\n",
    "# Metropolis Lab 1\n",
    "\n",
    "In class, many of you said you wanted to write your own [Metropolis algorithm](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm), so here's the lab! We worked with estimating the **mean** of a model in our first notebook, so let's estimate **standard deviation** in this notebook.\n",
    "\n",
    "This lab is to be done in class, in teams of 2. TAs will go around with the solution. You can ask for help at any step. TAs won't give you the solution, but they will help you find it. Answer all 10 questions in the notwbook (`a` to `i`), and post the notebook (one per team, with the name of both teammates on blackboard). We'll decide how to count this as bonus hw points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import matplotlib as mpl   \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data generation\n",
    "\n",
    "We generate 30,000 samples from a normal distribution with $\\mu$ = 10, and $\\sigma$= 3, but let's say we can only observe 1000 of them. \n",
    "\n",
    "Lab goal: We'll use Bayesian estimation to build a model from the 1000 observations, then we'll use the model to reconstruct (a simulation of) the 30,000 samples.\n",
    "\n",
    "Let's start by plotting the histogram of these observed 1000 datapoints.\n",
    "\n",
    "#### a) Please fill in the ellipses (...) below with code and plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:none;\">\n",
    "observation = population[np.random.randint(0, 30000, 1000)]\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.119179991500861"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=lambda mu, sig, t: np.random.normal(mu, sig, t)\n",
    "\n",
    "#Form a population of 30,000 individuals, with average=10 and sigma=3\n",
    "population = model(10, 3, 30000)\n",
    "\n",
    "#Assume we are only able to observe 1,000 of these individuals, sample randomly amongst the 30000:\n",
    "observation = np.random.choice(population,1000,replace=False)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist( observation,bins=35 ,)\n",
    "ax.set_xlabel(\"Value\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Figure 1: Distribution of 1000 observations sampled from a population of 30,000 with $\\mu$=10, $\\sigma$=3\")\n",
    "mu_obs=observation.mean()\n",
    "mu_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Which parameter to model\n",
    "\n",
    "$\\theta$ is made up of two values: $[\\mu,\\sigma]$. Let's assume  $\\mu$ is a constant, $\\mu = \\mu_{obs}$.\n",
    "\n",
    "We would like to find a distribution for $\\sigma_{obs}$ using the 1000 observed samples. \n",
    "\n",
    "Those with a math background will say that ***there is a formula for computing the standard deviation*** $\\sigma$ (actually, ***all of you need to know how to compute standard deviation from $n$ observations $d_i$ with mean $\\mu$***):\n",
    "\n",
    "$$\\sigma=\\sqrt{\\frac{1}{n}\\sum_i^n(d_i-\\mu)^2}$$\n",
    "\n",
    "Note however, we are not trying to find *a* value for $\\sigma$, but rather, we are trying to compute a distribution of the possible values of $\\sigma$.\n",
    "\n",
    "#### b) Compute the standard distribution of the 30,000 samples, and then the standard distribution of the 1,000 observations in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.119179991500861, 2.932208815929123)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_mu = np.mean(observation)\n",
    "observation_std = np.std(observation)\n",
    "\n",
    "observation_mu,observation_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.979563898986004, 3.0000667768505704)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_mu = np.mean(population)\n",
    "population_std = np.std(population)\n",
    "\n",
    "population_mu,population_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the pdf for the prior and pdf for the likelihood\n",
    "\n",
    "From the figure above, we can see that the data is **normally distributed**. The mean can be computed by taking the average of the values of the 1000 samples. By doing that, we get for example $\\mu_{obs}=9.8$.\n",
    "\n",
    "For the standard deviation $\\sigma$ pdf, let's pick a simple one: the normal distribution!\n",
    "\n",
    "\\begin{equation} \\sigma_{new} \\sim N(\\mu=\\sigma_{current},\\; \\sigma_q=1) \\end{equation}\n",
    "\n",
    "Note that $\\sigma_q$ is unrelated to $\\sigma_{new}$ and $\\sigma_{current}$. It simply specifies the standard deviation of the parameter space. It can be any value desired. It only affects convergence time of the algorithm.\n",
    "\n",
    "We don't have any preferences values that $\\sigma_{new}$ and $\\sigma_{current}$ can take, but they should be positive! Why?\n",
    "\n",
    "Standard deviation measures **dispersion**, which is a distance, and distances cannot be negative.\n",
    "\n",
    "$\\sigma=\\sqrt{\\dfrac{1}{n}\\sum_i^n(d_i-\\mu)^2}$, and the square root of a number cannot be negative. Make sure to strictly enforce this in your prior.\n",
    "\n",
    "Since likelihood $f$ should be proportional to the posterior, we choose $f$ to be the following pdf, for each data point $d_i$ in the data D:\n",
    "\n",
    "\\begin{equation} f(d_i\\;|\\; \\mu,\\sigma^2) = \\dfrac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\dfrac{(d_i-\\mu)^2}{2\\sigma^2}} \\end{equation}\n",
    "\n",
    "#### c) Write a python function to evaluate $f$ above and plot f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sig):\n",
    "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
    "\n",
    "def calc_likelihood_analytical(data,x,mu,sig):\n",
    "    likelihood = np.exp(-np.power(data-mu,2.)/(2*np.power(sig,2)))/np.sqrt(2*np.pi*np.power(sig,2))\n",
    "    mu_likelihood = np.mean(likelihood);\n",
    "    sig_likelihood = np.std(likelihood);\n",
    "    return norm(mu_likelihood,sig_likelihood).pdf(x)\n",
    "\n",
    "def calc_likelihood_analytical_(data,mu,sig):\n",
    "    return np.exp(-np.power(data-mu,2.)/(2*np.power(sig,2)))/np.sqrt(2*np.pi*np.power(sig,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax1 = plt.subplot()\n",
    "ax2 = plt.subplot()\n",
    "x = np.linspace(-0.5,0.5,1000)\n",
    "\n",
    "prior_sig = gaussian(x,0,1)\n",
    "# likelihood_sig = calc_likelihood_analytical_(x, 0., 3.)\n",
    "likelihood_sig = calc_likelihood_analytical(observation,x,0.,1.)\n",
    "\n",
    "\n",
    "ax1.plot(x, prior_sig,color=\"blue\")\n",
    "ax2.plot(x,likelihood_sig,color=\"red\")\n",
    "ax1.set(xlabel='sig', ylabel='belief', title='Analytical prior & likelihood');\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5269644399718774e-07"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = norm(observation_mu, 5)\n",
    "a.pdf([1,2,3,4]).prod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define when we accept or reject $\\sigma_{new}$: \n",
    "We accept $\\sigma_{new}$ from $\\sigma_{current}$ if and only if:\n",
    "\n",
    "$\\dfrac{\\text{Likelihood}(D \\;|\\; \\mu_{obs},\\sigma_{new})\\; * \\; \\text{prior}(\\mu_{obs},\\sigma_{new})}{\\text{Likelihood}(D\\;|\\;\\mu_{obs},\\sigma_{current})\\;*\\;\\text{prior}(\\mu_{obs},\\sigma_{current})} \\;\\;>\\;\\; 1     \\quad \\quad \\quad \\quad \\quad      (1)$\n",
    "\n",
    "If this ratio is smaller or equal to 1, then we compare it to a uniformly generated random number in the closed set [0,1]. If the ratio is larger than the random number, we accept $\\sigma_{new}$, otherwise we reject it.\n",
    "\n",
    "*Note: Since we will be computing this ratio to decide which parameters should be accepted, make sure that the adopted likelihood is proportional to the posterior itself, $P(\\sigma\\;|\\; D,\\mu)$, which in our case is true.*\n",
    "\n",
    "\n",
    "## Step 5: Acceptance condition derivation:\n",
    "\n",
    "The **total** likelihood for a set of observations $D$ is: $\\text{Likelihood}(D\\;|\\;\\mu_{obs},\\sigma_{new}) = \\prod_i^n f(d_i\\;|\\;\\mu_{obs},\\sigma_{new}) $\n",
    "\n",
    "In our case, we will **log** both the prior and the likelihood function. Why log? Simply because it helps with \n",
    "**numerical stability**, i.e. multiplying thousands of small values (probabilities, likelihoods, etc..) can cause an **underflow** in  system memory, and the **log** is a perfect solution (remember the problems we had with our previous notebook?) because it transforms multiplications to **additions** and small positive numbers into not-so-small negative numbers.\n",
    "\n",
    "Therefore our acceptance condition from equation $(1)$ above becomes, after taking the **log** of equation (1):\n",
    "\n",
    "Accept $\\sigma_{new}$ if:\n",
    "\n",
    "$$Log(\\text{Likelihood}(D\\;|\\;\\mu_{obs},\\sigma_{new})) + Log(\\text{prior}(\\mu_{obs},\\sigma_{new})) - (Log(\\text{Likelihood}(D\\;|\\:\\mu_{obs},\\sigma_{current})) + Log(prior(\\mu_{obs},\\sigma_{current})))\\;>\\;0$$\n",
    "\n",
    " $\\quad$\n",
    "\n",
    " And that is equivalent to:\n",
    " \n",
    " $$\\sum_i^nLog(f(d_i\\;|\\;\\mu_{obs},\\sigma_{new})) + Log(\\text{prior}(\\mu_{obs},\\sigma_{new})) - \\sum_i^nLog(f(d_i\\;|\\;\\mu_{obs},\\sigma_{current}))-Log(\\text{prior}(\\mu_{obs},\\sigma_{current}))>0$$\n",
    " \n",
    " $\\quad$\n",
    " \n",
    " \n",
    "which is equivalent to: \n",
    "  \n",
    "$$\\sum_i^n -nLog(\\sigma_{new}\\sqrt{2\\pi})-\\dfrac{(d_i-\\mu_{obs})^2}{2\\sigma_{new}^2} + Log(prior(\\mu_{obs},\\sigma_{new})) \\quad > \\quad \\sum_i^n -nLog(\\sigma_{current}\\sqrt{2\\pi})-\\dfrac{(d_i-\\mu_{obs})^2}{2\\sigma_{current}^2}+Log(prior(\\mu_{obs},\\sigma_{current})) \\quad \\quad  (2)$$\n",
    "\n",
    "So let's write some code:\n",
    "\n",
    "#### d) Please fill in the ellipses below for `prior` and `manual_log_likelihood`\n",
    "\n",
    "Note that x are our **unknowns**: the parameters $\\mu$ and $\\sigma$ (in our case $\\mu$ is fixed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The transition model defines how to move from sigma_current to sigma_new: we use numpy's \n",
    "# gaussian-distributed random number generator\n",
    "transition_model = lambda x: [x[0], np.random.normal(x[1], 0.5, (1,))]\n",
    "\n",
    "def prior(x):\n",
    "    # the input is a 2-element list\n",
    "    # x[0] = mu, x[1]=sigma (new or current)\n",
    "    # returns 1 for all **valid** values of sigma. \n",
    "    return norm(x[0],x[1])\n",
    "\n",
    "# Likelihood of the data given a sigma, whether new or current, according to our equation #2 above\n",
    "def manual_log_likelihood(x, data):\n",
    "    # x[0] = mu, x[1] = sigma \n",
    "    # data = observations\n",
    "    mu = x[0]\n",
    "    sig = x[1]\n",
    "    likelihood = np.exp(-np.power(data-mu,2.)/(2*np.power(sig,2)))/np.sqrt(2*np.pi*np.power(sig,2))\n",
    "    mu_likelihood = np.mean(likelihood);\n",
    "    sig_likelihood = np.std(likelihood);\n",
    "    return np.sum(np.log(norm(mu_likelihood,sig_likelihood).pdf(data)))\n",
    "\n",
    "#Same as manual_log_likelihood(x, data), using scipy\n",
    "def log_likelihood(x, data):\n",
    "    # x[0] = mu, x[1] = sigma\n",
    "    # data = observations\n",
    "    return np.sum(np.log(scipy.stats.norm(x[0], x[1]).pdf(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Please write your own Metropolis algorithm below\n",
    "\n",
    "Note that `likelihood_computation(x,data)` is the **likelihood** that parameters x generated the data. That will the function `manual_log_likelihood` written above.\n",
    "\n",
    "`transition_model(x)`: is a function that draws a sample from a symmetric distribution and returns it.\n",
    "\n",
    "`param_init` is the starting sample. So you start your Metropolis program with `x = param_init`\n",
    "\n",
    "`iterations` is the number of accepted to generated\n",
    "\n",
    "`data` are the observations we wish to model\n",
    "\n",
    "`acceptance_rule(x, x_new)` is a predicate that decides whether to accept or reject the new sample.\n",
    "\n",
    "So, start with x equal to `param_init`, and with two lists, one are the accepted values, the other the rejected values.\n",
    "\n",
    "Then for index i ranging in `range(iterations)`, set `x_new` equal to `transition_model(x)`, and `x_likely` to `likelihood_computation(x, data)`. Then evaluate a new candidate `x_new_likely` in the same way.\n",
    "\n",
    "Then plug in equation (2) as input to your `acceptance_rule`. Equation (2) can simply be written as comparing `(x_likely + np.log(prior(x))` to `(x_new_likely + np.log(prior(x_new))`. If the new value `x_new` is accepted, replace `x` with `x_new` in order to start the next iteration, and add `x_new` to the accepted list. If the new value `x_new` is rejected, then just add it to the rejected list.\n",
    "\n",
    "At the end of `iterations`, return the accepted list and the rejected list as numpy arrays (`np.array()`).\n",
    "\n",
    "Simple, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicate whether to accept or reject the new sample\n",
    "def acceptance(x, x_new):\n",
    "    if x_new > x:\n",
    "        return True\n",
    "    else:\n",
    "        accept=np.random.uniform(0,1)\n",
    "        # Since we want a **log** likelihood, we want to exponentiate \n",
    "        # in order to compare to the random number. Make sure less\n",
    "        # likely x_new are less likely to be accepted\n",
    "        return (accept < (np.exp(x_new - x)))\n",
    "\n",
    "# Write a metropolis algorithm:\n",
    "def metropolis_hastings(likelihood_computation, \n",
    "                        prior, \n",
    "                        transition_model, \n",
    "                        param_init, \n",
    "                        iterations, \n",
    "                        data, \n",
    "                        acceptance_rule):\n",
    "    \n",
    "    x = param_init;\n",
    "    accepted = [x[1]]\n",
    "    rejected = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        # suggest new position\n",
    "        x_new = transition_model(x)\n",
    "        \n",
    "        # Compute likelihood by multiplying probabilities of each data point\n",
    "        x_likely = likelihood_computation(x,data)\n",
    "        x_new_likely = likelihood_computation(x_new,data)\n",
    "        \n",
    "        # Compute prior probability of current and proposed sigma\n",
    "        if acceptance_rule(x_likely + np.log(prior(x)),(x_new_likely + np.log(prior(x_new)))):\n",
    "            x = x_new\n",
    "            accepted.append(x[1])\n",
    "        else:\n",
    "            rejected.append(x_new[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run the algorithm with initial parameters and collect `accepted` and `rejected` samples\n",
    "\n",
    "Run your Metroplois algorithm with the following parameters:\n",
    "\n",
    "- manual_log_likelihood\n",
    "- prior\n",
    "- transition_model\n",
    "- [mu_obs,0.1]\n",
    "- 50000\n",
    "- observation\n",
    "- acceptance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted, rejected = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rejected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm accepted how many samples (which might be different on each new run)?\n",
    "\n",
    "#### f) What are the last 10 samples for $\\sigma$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accepted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g) Plot accepted and rejected values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "\n",
    "ax.plot( rejected[0:50,1], 'rx', label='Rejected',alpha=0.5)\n",
    "ax.plot( accepted[0:50,1], 'b.', label='Accepted',alpha=0.5)\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"$\\sigma$\")\n",
    "ax.set_title(\"$\\sigma$ sampling with Metropolis. First fifty samples\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "ax2 = fig.add_subplot(2,1,2)\n",
    "to_show=-accepted.shape[0]\n",
    "ax2.plot( rejected[to_show:,1], 'rx', label='Rejected',alpha=0.5)\n",
    "ax2.plot( accepted[to_show:,1], 'b.', label='Accepted',alpha=0.5)\n",
    "ax2.set_xlabel(\"Iteration\")\n",
    "ax2.set_ylabel(\"$\\sigma$\")\n",
    "ax2.set_title(\"$\\sigma$ sampling with Metropolis, all samples\")\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "accepted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### h) So, starting from an initial σ of 0.1, the algorithm converges pretty quickly to which expected value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, consider the initial 25% of the values of $\\sigma$ to be \"burn-in\", so ***drop them***.\n",
    "\n",
    "Visualize the trace of  $\\sigma$ and the histogram of the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show=int(-0.75*accepted.shape[0])\n",
    "hist_show=int(-0.75*accepted.shape[0])\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.plot(accepted[show:,1])\n",
    "ax.set_title(\"Trace for $\\sigma$\")\n",
    "ax.set_ylabel(\"$\\sigma$\")\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ax.hist(accepted[hist_show:,1], bins=20,density=True)\n",
    "ax.set_ylabel(\"Frequency (normed)\")\n",
    "ax.set_xlabel(\"$\\sigma$\")\n",
    "ax.set_title(\"Histogram of $\\sigma$\")\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "ax.grid(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most likely value for $\\sigma$ is around what value? A bit more or less than the original value of 3.0? The difference is due to observing only 3% f the original population (1,000 out of 30,000) \n",
    "\n",
    "## Predictions:\n",
    "\n",
    "#### i) First, average out the last 75% of accepted samples of σ, and then generate 30,000 random individuals from a normal distribution with μ=9.8 and your value of σ. \n",
    "\n",
    "Then compare against the original data of 30,000 individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu=accepted[show:,0].mean()\n",
    "sigma=accepted[show:,1].mean()\n",
    "print(mu, sigma)\n",
    "model = lambda t,mu,sigma:np.random.normal(mu,sigma,t)\n",
    "observation_gen=model(population.shape[0],mu,sigma)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist( observation_gen,bins=70 ,label=\"distribution of 30,000 individuals, predicted\")\n",
    "ax.hist( population,bins=70 ,alpha=0.5, label=\"Values of the 30,000 individuals, original\")\n",
    "ax.set_xlabel(\"Mean\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Predictions posterior distribution\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is it a good fit? \n",
    "\n",
    "Your model generated, from a small 1,000 sample of 30,000 observations, a model of ***all 30,000 observations***!\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The great thing about probabilistic programming is that you only need to write down the model and then run it. The simplest MCMC algorithm, [Metropolis](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm), is very simple. There is no need to compute evidence (denominator), or ensure constraining mathematical properties. Once you have a good model, it essentially **simulates** the data, so you can throw away all your data and use your model to predict new data. If your model is low dimensional, then you turned something complicated into something very easy. Well done! Your brain loves you! That's called **intelligence**!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
