{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">INFO 6105 Data Science Eng Methods and Tools, Lecture 10 day 2</div>\n",
    "<div style=\"text-align: right\">Dino Konstantopoulos, 20 November 2019</div>\n",
    "\n",
    "# The Winnow\n",
    "\n",
    "Let's work with a very simple ANN: One consisting of three layers: 2 **hidden** ones with 10 neurons each, and a single-neuron input and a single-neuron output. Then, let's revisit the **Winnow algorithm** with an **ensemble** methodology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Autoencoders with `Keras`\n",
    "\n",
    "Excting! We're going to start with `Keras` today, which is the main API behind `TensorFlow 2.0`. I've used `Keras` when it was still a baby, before anyone was saying anything about it, let alone the tensorflow team at Google.\n",
    "\n",
    "This is a single neuron in your brain. Pretty huh? Imagine is talking (we heard a recording of many neurons chirping together last lecture):\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src =ipynb.images/neuron1.png width = 400 />\n",
    "</center>\n",
    "\n",
    "\n",
    "And this is the artificial equivalent, with many inputs coming in from neighboring neurons. The bias is always there, independent of what the inputs are. The bias represents the neuron's ***learning experience***. After the **activation function** gets applied, the output goes to downstream neurons in the next layer.\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src =ipynb.images/neuron-many.png width = 400 />\n",
    "</center>\n",
    "\n",
    "The **activation function** is a non-linear sigmoidal function that transforms the electrochemical **input** potential to a different **output** potential. It is this **non-linearity** that produces the powerful model building capability for networks of neurons. Examples are CNNs, RNNs, and LSTM networks. However, we know based on our **Winnow** experience that even **linear** activation functions can produce effective learning models for simple datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A 2-layer model\n",
    "\n",
    "In our two layer model, with 10 neurons in each layers, and a total of 10 + 100 + 10 = 120 connections, we were able to autoencode a noisy sine function. \n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src =ipynb.images/neurons-10-10.png width = 150 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)\n",
    "x = np.linspace(0, 2 * math.pi, 200)\n",
    "sine = np.sin(x)\n",
    "err = np.random.normal(0, 0.2, len(sine))\n",
    "y = sine + err\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(x, y)\n",
    "plt.xlim([0, 2 * math.pi])\n",
    "plt.title('A noise sine')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this means is that we compressed the 200 datapoints resulting from a noisy sine function to a number of weights, by training our neural net. A keras `Dense` layer is really a *sandwich* of two **layers**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3.5.1\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n",
      "d:\\Anaconda3.5.1\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1, units=10)`\n",
      "  \n",
      "d:\\Anaconda3.5.1\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10)`\n",
      "  \n",
      "d:\\Anaconda3.5.1\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "d:\\Anaconda3.5.1\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26348532ba8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "n_conn = 10\n",
    "model = Sequential()\n",
    "model.add(Dense(output_dim=n_conn, input_dim=1)) #from 1 to 10\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=n_conn)) #from 10 to 10\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=1)) #from 10 to 1\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "X_train = np.array(x, ndmin=2).T\n",
    "Y_train = np.array(y, ndmin=2).T\n",
    "\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          nb_epoch=5000,\n",
    "          verbose=0,\n",
    "          callbacks=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many information layers in our neural net?\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src =ipynb.images/neuron-5layers.png width = 150 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many weights in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.07558671, -0.02731602,  0.56138307, -0.36878344,  0.10805937,\n",
       "         -0.44050014, -0.5521841 ,  0.30822212,  0.7508774 ,  0.4316021 ]],\n",
       "       dtype=float32),\n",
       " array([ 6.4156318e-01, -6.9355301e-06, -5.2596337e-01, -8.9821478e-06,\n",
       "         6.0990065e-01, -3.0197665e-05, -4.3725966e-05, -7.8251049e-02,\n",
       "        -1.3609480e+00,  5.2223366e-01], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.layers[0].get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.layers[1].get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.30330205,  0.14495201,  0.3118862 ,  0.45895725, -0.08304461,\n",
       "         -0.6304284 , -0.19051902,  0.17893852, -0.2843512 ,  0.20973974],\n",
       "        [-0.4584059 , -0.4557514 ,  0.08840276,  0.5015261 , -0.42041102,\n",
       "          0.24514784,  0.16964209,  0.5287002 , -0.09905362, -0.43667072],\n",
       "        [-0.25561795, -0.14615585,  0.28554448, -0.49693623,  0.09481683,\n",
       "          0.4911677 , -0.30012536, -0.1621637 ,  0.16567671,  0.5097417 ],\n",
       "        [ 0.21061802, -0.452083  ,  0.43860346, -0.22990361,  0.04520132,\n",
       "         -0.4112595 , -0.18610354,  0.35950506,  0.48901695, -0.22948715],\n",
       "        [-0.3685887 , -0.20687127, -0.3405207 ,  0.17285463,  0.59805703,\n",
       "         -0.4178629 , -0.34061575, -0.05700661, -0.42839903, -0.02827919],\n",
       "        [ 0.17112249, -0.21771677, -0.06919834,  0.3919421 ,  0.50938046,\n",
       "          0.49181682,  0.22317803,  0.07711881, -0.06585511,  0.05968007],\n",
       "        [ 0.45967752,  0.18730597, -0.02083023, -0.3213762 ,  0.24905762,\n",
       "         -0.54664415, -0.2595555 , -0.51936835, -0.3299557 ,  0.29791293],\n",
       "        [ 0.30877084, -0.47265202, -0.24932255,  0.17319657, -0.28676108,\n",
       "          0.38827398,  0.20322779,  0.29282504, -0.27381268,  0.32139146],\n",
       "        [-0.35585967, -0.44618133, -0.4778189 , -0.8766876 , -0.51775247,\n",
       "          0.73437643,  0.50773996, -0.49476546,  0.29114956,  0.18744063],\n",
       "        [ 0.21784109,  0.37280864,  0.1502814 ,  0.32689157, -0.4144306 ,\n",
       "         -0.7714444 ,  0.48842055,  0.22236843, -0.2707239 , -0.2798886 ]],\n",
       "       dtype=float32),\n",
       " array([-0.03387271, -0.05732011, -0.15063225,  1.1751083 ,  0.69188243,\n",
       "        -0.7288919 , -0.23673674,  0.1496778 , -0.01810089, -0.25570536],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.layers[2].get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.layers[3].get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.39283648],\n",
       "        [ 0.22326359],\n",
       "        [ 0.39553687],\n",
       "        [ 1.4749285 ],\n",
       "        [-1.0500176 ],\n",
       "        [ 1.2764152 ],\n",
       "        [ 0.30588096],\n",
       "        [ 0.7096248 ],\n",
       "        [ 0.66661406],\n",
       "        [ 0.34936446]], dtype=float32), array([-1.7696104], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.layers[4].get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "120 total weights! So we compressed 200 data points to 120 datapoints by building a lower-dimensional model (the neural net), which yields approximately the same data:\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src =ipynb.images/2layers.png width = 400 />\n",
    "</center>\n",
    "\n",
    "This is not different with the dimensionality reduction we accomplished in previous lectures where we modelled datasets as random variates from pdfs like the *gaussian, beta, gamma,* etc. By the way, our data compression rate in that case was much more dramatic as a gaussian takes only **two** parameters (mean and standard deviation), and can be a generative model for**huge** datasets!\n",
    "\n",
    "Our neural net is an example of an **autoencoder** because it encodes our original signal, in a lower dimensional space.\n",
    "\n",
    "We also used keras to build a CNN to classify images, and you can use professor's trained weights to figure out the data compression rate over 32 x 32 images. However, our CNN was not exactly an autoencoder, it is a classifier that classifies images in bins of cat, dog, bird, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Winnow\n",
    "\n",
    "Back to the simplest kind of learning network: The **Winnow**. And a different dataset.\n",
    "\n",
    ">**Winnowing** in english means to \"remove unwanted items*. It comes to us from [agriculture](https://en.wikipedia.org/wiki/Winnowing). In its simplest form in agriculture, it involves throwing a mixture into the air so that the wind blows away the lighter chaff (junk), while the heavier grains fall back down for recovery.\n",
    "\n",
    "We're going to train a binary classifier based on binary features by throwing away bad training results. That's the basic winnowing algorithm. Our goal is to predict one of two states on a collection of features. \n",
    "\n",
    ">**STATE**:To predict the state of an observation, check all the features that are *active* (true, or detected in an observation) and sum up the weights assigned to these features. If the total is above a certain threshold, the result is true, otherwise it’s false.\n",
    "\n",
    "The learning process feeds examples (observations with known labels) and progressively updates the weights ***when the model makes mistakes***. If the current model predicts the output correctly, ***don’t change anything***! If it predicts true but should predict false, it is over-shooting, so weights that were used in the prediction (i.e. weights attached to *active* features) are reduced (by half). Conversely, if the prediction is false but the correct result should be true, the active features are not used enough to reach the threshold, so they should be bumped up (doubled).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the algorithm:\n",
    "\n",
    "Initialize: weights $w_1 = w_2 = \\cdots = w_n=1$\n",
    "\n",
    "Iterate:\n",
    "\n",
    "Receive an example vector $x = {x_1, x_2, \\cdots x_n}$, with its label (true or false).\n",
    "\n",
    "Predict: \n",
    "Output 1 if …, 0 otherwise.\n",
    "\n",
    "Then, check the label.\n",
    "\n",
    "Update weights *only if making a mistake*:\n",
    "- False-positive error:  for each $x_i = 1$:\t$w_i = 2*w_i$\n",
    "- False-negative error: for each $x_i = 0$:\t$w_i = \\frac{w_i}{2} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words:\n",
    "\n",
    "```python\n",
    "initialize weights\n",
    "for each epoch:\n",
    "  for each training item X:\n",
    "    compute Y\n",
    "    if correct (Y == label) do nothing\n",
    "    else if incorrect:\n",
    "      if computed Y is too large:\n",
    "        divide all relevant weights by 2.0\n",
    "      else if computed Y is too small:\n",
    "        multiply all relevant weights by 2.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm starts with arbitrary initial weights of 1 for every feature.\n",
    "\n",
    "This is the **training process** (expressed in the cool language [F#](https://fsharp.org/) (*if you like being lazy because you can do a lot of programming by writing little code in python, it gets even better with functional languages like F#!*): Either double or halve the weights based on mistakes made:\n",
    "\n",
    "```python\n",
    "let update (theta:float) (alpha:float) (w:Weights) (ex:Example) =\n",
    "\tlet real,obs = ex\n",
    "\tmatch (real,predict theta w obs) with\n",
    "\t| (true,false) -> w |> Array.mapi (fun i x -> if obs.[i] then alpha * x else x)\n",
    "\t| (false,true) -> w |> Array.mapi (fun i x -> if obs.[i] then x / alpha else x)\n",
    "\t| _ -> w\n",
    "```\n",
    "\n",
    "And this is the **prediction function**, which takes in theta (the threshold), weight array, and an observation (features) array. Zip together the features and the weights, exclude the pairs where the feature is not active, sum the weights, and check whether the threshold is lower that the total:\n",
    "```python\n",
    "type Observation = bool []\n",
    "type Label = bool\n",
    "type Example = Label * Observation\n",
    "type Weights = float []\n",
    " \n",
    "let predict (theta:float) (w:Weights) (obs:Observation) =\n",
    "\t(obs,w) ||> Seq.zip\n",
    "\t|> Seq.filter fst\n",
    "\t|> Seq.sumBy snd\n",
    "\t|> ((<) theta)\n",
    "```\n",
    "\n",
    "The algorithm essentially drives the weights of irrelevant predictors to 0, *winnowing them out*. This makes Winnow classification effective in situations where many of the predictor variables are irrelevant (frivolous). Simple, right? :-)\n",
    "\n",
    ">**ANALOGY**: It's like you have an army of lieutenants, each of whose advice you heed. You train them with theoretical situations that you know the result of. If the total voice of all lieutenants is correct, do nothing. if it's wrong, the lieutenants that were right get their voices doubled, the ones that were wrong get their voices halved. In the end, the lieutenant's total vocal output should yield the correct result. The activation function is totally linear!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**DEEP LEARNING IN A NUTSHELL**: Machine Learing with Deep Learning (DL) algorithms is not much different in methodology. The modeling power of DL is much higher due to the artificial neuron’s inherent non-linearities. But the methodology is similar: \n",
    "Train model with feature observations in order to refine weights (synapse strength), use a guiding algorithm (e.g. stochastic gradient descent), and an error metric (e.g. root mean square). Once weights are determined, reuse them for any other observation with similar features. Most of the DL research in the last 20 years was about how to update the weights in training, whether to use a greedy model or not, which activation function to pick, how many layers and neurons per layer, and how to connect the neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lab: Winnow on MNIST\n",
    "\n",
    "Let's download the database of MNIST digits from [here](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src =ipynb.images/mnistexamples.png width = 400 />\n",
    "</center>\n",
    "\n",
    "I already downloaded these, uncompressed them, and put them on blackboard.\n",
    " \n",
    "The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. The images are centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.\n",
    "\n",
    "This is how we measure success, for each digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_macro_f1_score(predictions, true_labels):\n",
    "    true_positives = [0 for i in range(10)]\n",
    "    false_positives = [0 for i in range(10)]\n",
    "    false_negatives = [0 for i in range(10)]\n",
    "\n",
    "    if len(predictions) != len(true_labels):\n",
    "        print(\"bug in code, length of predictions should match length of true_labels\")\n",
    "        return None\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == true_labels[i]:\n",
    "            true_positives[predictions[i]] += 1\n",
    "        else:\n",
    "            false_positives[predictions[i]] += 1 #if predictions[100] = 5 and true_labels[100] = 9, then 5 was over-predicted \n",
    "            false_negatives[true_labels[i]] += 1 #... and 9 under-predicted\n",
    "\n",
    "    total_classes = 0\n",
    "    total_f1 = 0\n",
    "    for i in range(10):\n",
    "        if (true_positives[i]==0 and false_positives[i]==0):\n",
    "            continue\n",
    "        elif (true_positives[i]==0 and false_negatives[i]==0):\n",
    "            continue\n",
    "        prec = true_positives[i]*1.0/(true_positives[i] + false_positives[i])\n",
    "        recall = true_positives[i]*1.0/(true_positives[i]+false_negatives[i])\n",
    "        f1=0\n",
    "        if prec+recall != 0:\n",
    "            f1 = 2*prec*recall/(prec+recall)\n",
    "        total_classes += 1\n",
    "        total_f1 += f1\n",
    "    return total_f1*100.0/total_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we transform the data into numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename,'rb') as fp:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', fp.read(4))\n",
    "        shape = tuple(struct.unpack('>I', fp.read(4))[0] for d in range(dims))\n",
    "        np_array = np.frombuffer(fp.read(), dtype=np.uint8).reshape(shape)\n",
    "    return np_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each digit in MNIST is represented as a 28x28 dimensional vector, each cell having a value in the range \\[0,255\\]. \n",
    "\n",
    "We scale each data value to be 0 or 1 (we divide each cell value by 255 and round). We make the 2D vector into a 1D vector of size 28x28 = 784. This is a stadard procedure in image deep learning.\n",
    "\n",
    "We take the bias term and pass the input value 1 for that feature. So in total we have a 785 dimensional feature space. \n",
    "\n",
    "There are 60k traiing examples and 10k test examples. We will use the first 10k images in the training set for training, and all the images in the test set for testing. \n",
    "\n",
    "We should shuffle the training examples before training, we shuffle in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_file, label_file):\n",
    "    images = read_file(image_file)\n",
    "    labels = read_file(label_file)\n",
    "    if (len(labels) > 10000):\n",
    "        labels = labels[:10000]\n",
    "        images = images[:10000]\n",
    "    flag_array = images > 128\n",
    "    images.setflags(write=1)\n",
    "    \n",
    "    images[flag_array]=1\n",
    "    images[~flag_array]=0\n",
    "    images = images.reshape( (10000, 784))\n",
    "\n",
    "    labels = labels.reshape(-1,1)\n",
    "    data = np.concatenate((images, labels), axis=1)\n",
    "#     np.random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some utility functions. `get_true_label` is a 0-9 discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_label(digit, perceptron_type):\n",
    "    if digit == perceptron_type:\n",
    "        return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_features_labels` appends labels to the data, for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_labels(data, bias):\n",
    "    examples = data[:,:-1]\n",
    "    labels = data[:,-1]\n",
    "    examples = np.append(examples, bias, 1)\n",
    "    return examples, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`inference()` predicts the digit from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(test_data, weights):\n",
    "    data_size = len(test_data)\n",
    "    bias = np.ones((data_size,1))\n",
    "    examples, labels = get_features_labels(test_data, bias)\n",
    "    prediction = np.ones(data_size, dtype = int)\n",
    "    correct = 0\n",
    "    for i, example in enumerate(examples):\n",
    "        activation_values = np.sum(weights*example, axis = 1)\n",
    "        prediction[i] = np.argmax(activation_values)\n",
    "        if prediction[i] == labels[i]:\n",
    "            correct += 1\n",
    "#     print correct*1.0/data_size*100\n",
    "    return prediction, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_f1_score()` scores our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(test_data, weights):\n",
    "    prediction, true_labels = inference(test_data, weights)\n",
    "    f1_score = calculate_macro_f1_score(prediction, true_labels)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_winnow()` is our Winnow implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_winnow(train_data, num_epoches, factor, theta):\n",
    "    data_size = len(train_data)\n",
    "    # weights = np.ones((10,785))\n",
    "    '''\n",
    "    initialize weights for all 10 winnows randomly\n",
    "    ''' \n",
    "    weights = np.random.uniform(0.1,1,[10,785])\n",
    "\n",
    "    average_weights = np.zeros((10,785))\n",
    "    bias = np.ones((data_size,1))\n",
    "    for epoch in range(num_epoches):\n",
    "        np.random.shuffle(train_data)\n",
    "        examples, labels = get_features_labels(train_data, bias)\n",
    "        for i,example in enumerate(examples):\n",
    "            y_pred = np.sum(weights*example, axis = 1)\n",
    "            for j in range(0,10):\n",
    "                label = get_true_label(labels[i], j)\n",
    "                if label == 1 and y_pred[j] < theta:\n",
    "                    weights[j][example == 1] *= factor\n",
    "                elif label == -1 and y_pred[j] >= theta:\n",
    "                    weights[j][example == 1] /= factor\n",
    "            average_weights += weights    \n",
    "    return weights, average_weights           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preprocess the data to stay in a 2D plane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_size = 10000\n",
    "epochs = 50\n",
    "factor = 1.2 #less dramatic update than a factor of 2\n",
    "theta = 785\n",
    "path = 'data'\n",
    "\n",
    "train_data = preprocess(path + '/train-images.idx3-ubyte', path + '/train-labels.idx1-ubyte')\n",
    "test_data = preprocess(path + '/t10k-images.idx3-ubyte', path + '/t10k-labels.idx1-ubyte')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train 10 Winnows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "for i in tqdm(range(10)):\n",
    "    np.random.shuffle(train_data)\n",
    "    weights, avg_weights = train_winnow(train_data[:train_data_size], epochs, factor, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we did by comparing predictions with labels, on both the training and the test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score:  60.96223673178813\n",
      "Test F1 Score:  57.32969224708167\n"
     ]
    }
   ],
   "source": [
    "f1_score_train = get_f1_score(train_data[:train_data_size], weights)\n",
    "f1_score_test = get_f1_score(test_data, weights)\n",
    "\n",
    "print(\"Training F1 Score: \", f1_score_train)\n",
    "print(\"Test F1 Score: \", f1_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training score is not that great... But MNIST is a big dataset, and we do have a simple linear activation function after all.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
