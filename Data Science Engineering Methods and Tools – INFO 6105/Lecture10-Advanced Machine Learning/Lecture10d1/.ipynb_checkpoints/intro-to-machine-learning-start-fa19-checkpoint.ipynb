{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">INFO 6105 Data Science Eng Methods and Tools, Lecture 9</div>\n",
    "<div style=\"text-align: right\">Dino Konstantopoulos with material by [Jeff Heaton](https://www.heatonresearch.com) and Douglas Blank</div>\n",
    "\n",
    "# Introduction to ANNs in 10 steps\n",
    "\n",
    "In yhis notebook, we put everything we learned so far together and use this knowledge to introduce ANNs.\n",
    "\n",
    "\n",
    "## 1. What is AI?\n",
    "In the 1960s, scientists thought that one day computers could learn like human beings, and even become artifical human beings. Thus the terminology *Artificial Intelligence* was coined, and we dreamt that one day, we were going to live with robots amidst us, which we were going to program.\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src=\"images/thinkrobot.jpg\" width=400 />\n",
    "</center>\n",
    "\n",
    "In the mid 1980s, (American) scientists at Canadian univerisites (exiled in Canada because the NSF would not give them grants to study Artifical Neural Networks, thinking it was a dead end road) leveraged computing power and good statistical mathematics to demonstrate once and for all the predictive power of Artificial Neural Networks. \n",
    "\n",
    "That is when we realized that machines don't have to be programmed to be human, because we, humans (specifically, our human brains) are essentially statistical machines.\n",
    "\n",
    "</br >\n",
    "<center>\n",
    "<img src=\"images/anns.png\" width=600 />\n",
    "</center>\n",
    "\n",
    "> **SAMKHYA:** Old schools of epistemology already knew that intelligence *begins* with statistics. [Samkhya](https://en.wikipedia.org/wiki/Samkhya) philosophy, one of the oldest philosophical schools in India is an enumerationist philisophy with 3 recognized epistemological approaches: the senses, logical reasoning, and testimony. Testimony is what we learn from elders and gather from experience, i.e. statistically.\n",
    "\n",
    "> **WHAT ABOUT EMOTION?**: Emotion is the evolutionary trait that makes human beings ***want to do statistics*** when we wake up every morning. More specifically, reasoning is the **evolutionary advantage** and emotion is the Darwinian trait of human beings that enforces the evolutionary advantage: Emotion drives us to predict and challenges us to leverage our brain, which is a statistical machine that does geometry and algebra (reasoning) in order to predict. The same way that giraffes' long neck lets them eat the fruit of tall trees, emotion drives us to do math. When you wake up in the morning, instead of eating from tall trees. the first thing you want to do as a human is **math**. \n",
    "\n",
    "> **WHAT IS EMOTION?** What differentiates us from the animal kingdom is that we are a species that ***wants***. We ***want*** to click on **buy with 1 click** on Amazon. We ***want*** those washboard abs and that perfect girl/boyfriend. We ***want*** that perfect job and that is why we come to complicated classes like this one. We ***want*** more than giraffes do, and want ***is*** emotion.\n",
    "\n",
    "We have an *adjective* to describe our predictive prowess. If we don't want to predict very much, that is called ***stupid***. If we want to predict a lot, that is called ***smart***. When we're busy predicting we can't actually enjoy circumstances, so there is always a middle ground between smart and stupid that we strive for. If we have a lot of advantages in life (like a rich dad or washboard abs), then we don't have to predict very much (because our daddy's money or our abs are going to do the talking) so we can afford to be more stupid. If we don't have a lot of advantages on our side, we have to predict more to even things out, so we need to be smarter. And that is why our species rules the plant, and giraffes don't.\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src=\"images/giraffe.jpg\" width=500 />\n",
    "Wait, we don't?\n",
    "</center>\n",
    "\n",
    "But professor, I don't want to do math when I wake up! I want to go to the gym and cuddle up with my boyfriend. \n",
    "\n",
    "I say you want to do math..\n",
    "\n",
    "</br >\n",
    "<center>\n",
    "<img src=\"images/wakeup.jpg\" width=500 />\n",
    "</center>\n",
    "\n",
    "You want to go to the gym and select the machine that will give you the best washboard abs because you know washboard abs are sexy and your boyfriend loves washboard abs. \n",
    "\n",
    "</br >\n",
    "<center>\n",
    "<img src=\"images/washboardf.jpg\" width=200 />\n",
    "</center>\n",
    "\n",
    "You want to look at the face of your boyfriend and based on smile and frown patterns, you want to compute his *dominant eigenvector* in order to predict happiness. And he will do the same for you and predict your dominant eigenvector. And together, you will be happier.\n",
    "\n",
    "</br >\n",
    "<center>\n",
    "<img src=\"images/toon-kisskiss.jpg\" width=400 />\n",
    "</center>\n",
    "\n",
    "So you see, you **want** to do math all the time, and it is this *evolutionary trait* that makes human the #1 species on the planet, and not giraffes or sloths. Your brain is a giant **predictor** that uses past knowledge in order to help you take the right step to maximize your future happiness.\n",
    "\n",
    ">**BAYESIAN STATISTICS:** The \n",
    "Bayesian approach leverages prior knowledge about the distribution of data and model parameters. When new data is observed, the prior knowledge is *refined*. That is *statistical learning*.\n",
    "\n",
    ">**IS THAT IT?:** Is intelligence is nothing more that statistics? Does that mean that we're nothing but survival and pleasure machines? The fact that our brains are essentially statistical predicton machine and that emotion is the acquired evolutionary trait that drives us to *predict*, does not mean that is ***all*** our brain can do. *Character*, *personality*, *soul*, *spirituality*, and *Ishvara Pranidhana* (dedication, devotion, and surrender of the fruits of one’s practice to a higher power, the 5th Niyama in yoga) for example, are still important human characteristics.\n",
    "\n",
    "</br >\n",
    "<center>\n",
    "<img src=\"images/8limbs.png\" width=400 />\n",
    "</center>\n",
    "\n",
    "Many are convinced that the next revolution in computing will be *affective computing*, where we endow computers with emotion, to please us, but also for the purpose of giving them to the goal to improve their own algorithms through reinforcement learning. \n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src=\"images/sadrobot.jpg\" width=300 />\n",
    "</center>\n",
    "\n",
    ">**DEFINITION**: *Machine Learning is a field of study that gives computers the ability to learn without being explicitly programmed* (Arthur Samuel, 1959), more specifically, the ability to *predict* missing columns of rows of data **based on a few columns** or **many many rows of *many many* columns**.\n",
    "\n",
    "Machine Learning algorithms are divided into the following categories:\n",
    "\n",
    "**Supervised Learning** : training data includes the **correct** answer (label)\n",
    "    <ul><li>Regression - algorithms that predict **continuous** outputs</li>\n",
    "        <li>Classification - algorithms that predict **discrete** outputs</li>\n",
    "    </ul>\n",
    "\n",
    "**Unsupervised Learning** : problems where the algorithm is given a data set without any “right answers”. The objective is to find some underlying structure in the data, e.g. clustering (missing columns everywhere). Many researchers think that this is the future of AI. See Yann LeCunn's famous [cake analogy](https://medium.com/syncedreview/yann-lecun-cake-analogy-2-0-a361da560dae).\n",
    "<br/><br/>\n",
    "**Reinforcement Learning** : problems where a [sequence of decisions](https://en.wikipedia.org/wiki/Reinforcement_learning) are made as opposed to a single decision (or prediction) in order to exhibit a more human-like behavior\n",
    "<br/><br/>\n",
    "**Learning Theory** : study of how and why (mathematically) a learning algorithm works\n",
    "\n",
    "\n",
    "</br >\n",
    "<center>\n",
    "<img src=\"images/mlalgos.png\" width=500 />\n",
    "</center>\n",
    "\n",
    "The more important techniques are *linear regression* (supervised), *linear classification* (unsupervised), *regression trees and forests* (unsupervised), and *artificial neural networks* (supervised). We covered the former in class, we are now getting ready to cover the latter.\n",
    "\n",
    "\n",
    ">**ABOUT INTELLIGENCE**: Intelligence, or more specifically **prediction-power** or modelling power, is the Darwinian evolutionary trait we acquired as humans that allowed us to dominate the planet (enforced through the physical mechanism of emotion). We seem to think that **intelligence** is the most important charactersitic of advanced species and that is why we are attempting to locate other intelligent species in our universe. However, in different solar systems, other genetic traits may be more important. For example, imagine a world where redness, or shape-shifting, is more important than intelligence, because being red or a shape-shifter confers an advantage to you over other species. In that case, red shape-shifting species would be looking for other red shape-shifting species in the universe, not necessarly intelligent ones.\n",
    "\n",
    "\n",
    "</br >\n",
    "<center>\n",
    "<img src=\"images/red-octopus.jpg\" width=500 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bayesian approach and Frequentist approach to modeling\n",
    "\n",
    "### Bayesian approach\n",
    "\n",
    "This is *Bayes' theorem*: <br/><br/>\n",
    "$p(Y|X) = \\frac{p\\left(X|Y\\right)p\\left(Y\\right)}{p\\left(X\\right)}$\n",
    "<br/><br/>\n",
    "\n",
    "Assume, that we model some process where the model has \n",
    "**free parameters** contained in the vector $\\mathbf{w}$. **Free parameters** means we haven't fully constrained $\\mathbf{w}$. Now assume that we have some notion of the probability distribution of these parameters, $p(\\mathbf{w})$,\n",
    "called the *prior*. That is, we assume that **some** set of values is the **best choice** \n",
    "for $\\mathbf{w}$ with some probability $p(\\mathbf{w})$. \n",
    "\n",
    "Now, assume that we observe a set of data, $\\mathbf{D}$, for the output we are attempting to predict with our model. Our objective is to solve a *reverse problem*: find\n",
    "the *best* set of parameters $\\mathbf{w}$ yielding the observed data. How we choose the *best* set is the challenge of machine learning. But once you find that model, you have *learned* the data by modeling the process that generates it. We did this in class with the probabilistic library `PyMc3`. So if I give you datapoints and you look at its histogram and you guess a good analytic model of that histogram (e.g. a *beta* distribution), then `PyMC3` will find the **free parameters** for you with a probabilistic algorithm like Metropolis or NUTS.\n",
    "\n",
    "In the Bayesian approach we attempt to maximize the *the probability of the parameters given the data*, \n",
    "$p(\\mathbf{w}|D)$, known as the *posterior*. Using Bayes' theorem we can express the *posterior* as <br/><br/>\n",
    "\n",
    "$p(\\mathbf{w}|D) = \\frac{p(D|\\mathbf{w})p(\\mathbf{w})}{p(D)}$ <br/><br/>\n",
    "\n",
    "In order to apply a Bayesian approach, we must formulate models for both the *prior*, $p(\\mathbf{w})$, and the *likelihood function*, $p(D|\\mathbf{w})$. Given\n",
    "these models and some data, we can compute appropriate values for our free parameter vector $\\mathbf{w}$ by maximizing \n",
    "$p(\\mathbf{w}|D)$, which is proportional ($\\propto$) to $p(D|\\mathbf{w})p(\\mathbf{w})$. \n",
    "\n",
    "### Frequentist approach\n",
    "\n",
    "The frequentist approach, of which **maximum likelihood estimation** (MLE) is one possible method, ignores the formulation of a *prior*, and goes directly to maximizing the likelihood function to find the model parameters. Thus, the frequentist approach can be described as maximizing *the probability of the data given the parameters*.\n",
    "\n",
    "A frequentist approach views the data $D$ as **fixed** and attempts to determine the model parameters $w$ by maximizing the likelihood function $p(D|\\mathbf{w})$.\n",
    "\n",
    "We assume we have specified a probability density model $p_{\\mathbf{w}}(d)$ for the observed data elements ${d_i \\in D}$ that is parameterized by $\\mathbf{w}$, i.e. $p$ is a **parametric model** for the distribution of $D$. \n",
    "\n",
    "For example, if $D$ has a **normal distribution** with mean $\\mu$ and variance $\\sigma^2$ (in which case the model $w$ is fully determined when $\\mu$ and $\\sigma$ are determined), then \n",
    "\n",
    "$$p_{\\mathbf{w}}(d) = \\frac{1}{\\sqrt{2 \\pi} \\sigma} e^{-(d-\\mu)^2/2\\sigma^2}$$\n",
    "\n",
    "and the likelihood function for our data and model is\n",
    "\n",
    "$$L(\\mathbf{w}, D) = \\prod_{i=1}^N p_{\\mathbf{w}}(d_i)$$\n",
    "\n",
    "where $N$ is the number of elements in $D$. That's because the probabiliy of $a$ and $b$ happening is $p(a) * p(b)$ if $a$ and $b$ are independent events. Thus the likelihood function is simply the product of the probability of each individual data point $d_i \\in D$ under the probability model $p_{\\mathbf{w}}$, implicitly assuming these data points are independent events. \n",
    "\n",
    "Out of mathematical convenience, we will most often work with the *log-likelihood* function (which turns the product into a sum by properties of the log function), i.e. the logarithm of $L(\\mathbf{w}; D)$\n",
    "\n",
    "$$l(\\mathbf{w};D) = \\sum_{i=1}^N \\log p_{\\mathbf{w}}(d_i)$$\n",
    "\n",
    "because $\\log(ab) = \\log(a) + \\log(b)$. Why can we do this? Because the logarithm of a function ***does not change the monotonicity*** (increasing or decreasing) of the function, it just crunches down its shape.\n",
    "\n",
    "The method of maximum likelihood chooses the value $\\mathbf{w} = \\widehat{\\mathbf{w}}$ that maximizes the *log-likelihood* function above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear Regression and the *General Linear Model*\n",
    "\n",
    "*Assume* that the target variable (what we have to guess, based on the independent variable $x$ (e.g. your boyfriend's mood based on his facial expression $x$) is described by <br/><br/>\n",
    "    $t = y(\\mathbf{x},\\mathbf{w}) + \\epsilon$\n",
    "    <br/><br/>\n",
    "where $y(\\mathbf{x},\\mathbf{w})$ is an as of yet undefined function of $\\mathbf{x}$ and $\\mathbf{w}$, and $\\epsilon$ is a <font color=\"red\"><em>Gaussian</em></font> distributed noise component. \n",
    "\n",
    "Let's define a **model** for $y(\\mathbf{x},\\mathbf{w})$. The *general linear regression* model is defined as follows\n",
    "\n",
    "$$y(\\mathbf{x},\\mathbf{w}) = \\sum_{j=0}^{M-1} w_j\\phi_j(\\mathbf{x}) = \\mathbf{w}^T\\mathbf{\\phi}(\\mathbf{x})$$\n",
    "\n",
    "where $\\mathbf{x}$ is a $D$ dimensional input vector, $M$ is the number of free parameters in the model, $\\mathbf{w}$ is a column vector of the free parameters, and \n",
    "\n",
    "$$\\phi(\\mathbf{x}) = {\\phi_0(\\mathbf{x}),\\; \\phi_1(\\mathbf{x}), \\ldots,\\;\\phi_{M-1}(\\mathbf{x})}$$\n",
    "\n",
    "with \n",
    "\n",
    "$$\\phi_0(\\mathbf{x})=1$$\n",
    "\n",
    "$\\phi$ is a set of **basis functions** where \n",
    "    each $\\phi_i$ is a real valued function \n",
    "    $\\\\{f \\in \\mathbf{R}^D\\Rightarrow\\mathbf{R}^1\\\\}$. \n",
    "    \n",
    "**Basis functions** means you can express *any* function as a linear combination of these basis functions, much like you can express any 3D vector as a linear combination of the basis functions $(1,0,0)$, $(0,1,0)$, and $(0,0,1)$. \n",
    "\n",
    ">**Eigenvectors** are an example of basis vectors. Much like you can express a general vector as a lineat combination of basis vectors, you can also express a general function as a linear combination of basis functions.\n",
    "    \n",
    "It is important to note that the set of basis functions, $\\phi$, <font color=\"red\">*need\n",
    "not be linear*</font> with respect to $\\mathbf{x}$. That is why this model is called the ***general* linear regression** (GLM) model. Gaussian Processes (GPs) are an example of GLM because the basis functions (e.g. the Matern) are not linear with respect to $\\mathbf{x}$.\n",
    "\n",
    "Further, note that this model defines an entire class of models. In order to \n",
    "contruct an actual predictive model for some observable quantity, we will have to make a further assumption on the choice of the set of basis functions, $\\phi$. \n",
    "\n",
    "Note that that $\\mathbf{w}^T$ is an $1 \\times M$ vector and that $\\mathbf{\\phi}(\\mathbf{x})$ is a $M \\times 1$ vector so that the target, $y$ is a scalar. This can be extended to $K$ dimensional target variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Maximum Likelihood Estimation (MLE) is equivalent to least squares error\n",
    "\n",
    "We first obtain observation training data, $\\mathbf{t}$, and the *best* value of $\\mathbf{w}$, is that which maximizes the likelihood function, $p(\\mathbf{t}\\;|\\;\\mathbf{w})$.\n",
    "\n",
    "Under the Gaussian noise condition it can be shown \\[`math snip snip..`\\] that the maximum likelihood function for the training data is:\n",
    "    \n",
    "$$p(\\mathbf{t}\\;|\\;\\mathbf{X},\\mathbf{w},\\sigma^2) = \\prod_{n=1}^N \\mathcal{N}(t_n\\;|\\;\\mathbf{w}^T\\phi(\\mathbf{x}_n),\\;\\sigma^2) = \\prod_{n=1}^N \\mathcal{N}(\\mathbf{w}^T\\phi(\\mathbf{x}_n)@t_n,\\;\\sigma^2)$$\n",
    "    \n",
    "where $\\mathbf{X}=\\{\\mathbf{x}_1,\\ldots,\\mathbf{x}_N\\}$ is the input value set for the corresponding $N$ oberved output values contained in the vector \n",
    "$\\mathbf{t}=\\{\\mathbf{t}_1,\\ldots,\\mathbf{t}_N\\}$, and $\\mathcal{N}(\\mu,\\sigma^2)$ is the normal distribution (Gaussian).\n",
    "    \n",
    "Thus, taking its base $e$ log:\n",
    "\n",
    "$$\\ln(p(\\mathbf{t}\\;|\\;\\mathbf{X},\\mathbf{w},\\sigma^2)) =\\frac{N}{2}\\ln\\frac{1}{\\sigma^2} -\\frac{N}{2}\\ln(2\\pi) - \\frac{1}{2\\sigma^2}\\sum_{n=1}^N\n",
    "    \\{t_n -\\mathbf{w}^T\\phi(\\mathbf{x}_n)\\}^2$$\n",
    "    \n",
    "Setting the derivative with respect to $\\mathbf{w}$ of the logarithm of the maximum likelihood above equal to zero, one can obtain \\[`math snip snip..`\\] the maximum likelikhood parameters given by the <em>normal equations</em>:\n",
    "    \n",
    "$$\\mathbf{w}_{ML} = \\left(\\mathbf{\\Phi}^T\\mathbf{\\Phi}\\right)^{-1}\\mathbf{\\Phi}^T\\mathbf{t}$$\n",
    "\n",
    "where $\\Phi$ is the $N \\times M$ <em>design matrix</em> with elements $\\Phi_{n,j}=\\phi_j(\\mathbf{x}_n)$, and $\\mathbf{t}$ is the $N \\times K$\n",
    "    matrix of training set target values (for $K=1$, it is simply a column vector). Note that $\\mathbf{\\Phi}^T$ is a $M \\times N$ matrix, so that $\\mathbf{w}_{ML}=\\left(\\mathbf{\\Phi}^T \\mathbf{\\Phi}\\right)^{-1}\\mathbf{\\Phi}^T\\mathbf{t}$ is \n",
    "$(M \\times N)\\times(N \\times M)\\times(M\\times N)\\times(N \\times K) = M \\times K$, where $M$ is the number of free parameters and $K$ is the number of predicted \n",
    "target values for a given input. <br/>\n",
    "</p>\n",
    "\n",
    "Note that the only term in the likelihood function that depends on $\\mathbf{w}$ is the last term. Thus, *<font color=\"red\">maximizing the likelihood\n",
    "function with respect to $\\mathbf{w}$ __under the assumption of Gaussian noise__ is equivalent to minimizing a \n",
    "sum-of-squares error function</font>*  $\\sum_{n=1}^N\n",
    "    \\{t_n -\\mathbf{w}^T\\phi(\\mathbf{x}_n)\\}^2$. That is why a probabilistic optimization problem reduces to a least-square problem.\n",
    "\n",
    "The quantity, $\\mathbf{\\Phi}^\\dagger=\\left(\\mathbf{\\Phi}^T\\mathbf{\\Phi}\\right)^{-1}\\mathbf{\\Phi}^T$ is known as the \n",
    "[**Moore-Penrose pseudo-inverse**](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse) of $\\Phi$. When $\\Phi^T\\Phi$ is invertible, the pseudo-inverse is \n",
    "equivalent to the inverse. When this condition fails, the pseudo-inverse can be found with techniques such as **singular value decomposition** (SVD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Linear basis function\n",
    "\n",
    "Let's generate data for $y = m*x + b + \\epsilon $ where $\\epsilon$ is a random Gaussian component with zero mean. \n",
    "    \n",
    "Given this data, let's apply the maximum likelihood solution to find values for parameters $m$ and $b$. \n",
    "\n",
    "Given that we know our data is linear, we chose basis functions $\\phi_0(x)=1$ and $\\phi_1(x)=x$. Thus, our \n",
    "our model will be $y=\\theta_0\\phi_0(x) + \\theta_1\\phi_1(x)$, where presumably the solution should yield $\\theta_0 \\approx b$ and $\\theta_1 \\approx m$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# in order to compare between examples, set a seed in random\n",
    "seed = 123456789\n",
    "np.random.seed(seed)\n",
    "\n",
    "def y(x,m,b,mu=0,sigma=1): \n",
    "    return m*x + b + np.random.normal(mu,sigma,1)[0]\n",
    "\n",
    "# training data, with N data points\n",
    "N = 101\n",
    "M = 2\n",
    "t = np.empty(N)\n",
    "domain_bound = 1.0 / N\n",
    "domain = np.empty(N)\n",
    "\n",
    "for i in range(N): \n",
    "    domain[i] = i * domain_bound\n",
    "    \n",
    "for i in range(N): \n",
    "    t[i] = y(x=domain[i],m=4.89,b=0.57)\n",
    "    \n",
    "# design matrix, phi, N X M: basis functions $\\phi_0(x)=1$ and $\\phi_1(x)=x$\n",
    "phi = np.array([np.ones(N), domain]).T\n",
    "print(phi[0:5])\n",
    "\n",
    "# find the solution. In this case case phi.T * phi is invertible, so do the folloing:\n",
    "temp1 = np.linalg.inv(np.dot(phi.T,phi)) #inverse of phi.T X phi\n",
    "temp2 = np.dot(temp1, phi.T)\n",
    "w1 = np.dot(temp2,t) #solution\n",
    "print('w1=', w1)\n",
    "\n",
    "# assuming that phi.T X phi was not invertible we could find the pseudo inverse using the pinv function.\n",
    "# We expect to obtain the same solution!\n",
    "phi_pi = np.linalg.pinv(phi)\n",
    "w2 = np.dot(phi_pi,t)\n",
    "print('w2=', w2)\n",
    "\n",
    "# compute the model predicted values for the training data domain\n",
    "predicted_t = [w2[0]+w2[1]*x for x in domain]\n",
    "plt.plot(domain,t)\n",
    "plt.plot(domain,predicted_t)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**ALGEBRA & GEOMETRY**: neat, this is MLE and yet it looks just like linear least squares! Isn't it neat how we do [algebra](https://en.wikipedia.org/wiki/Algebra), and it looks like [geometry](https://en.wikipedia.org/wiki/Geometry)? Your brin works the same way: Your neurons do linear algebra, but their output is high-dimensional surfaces that model experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Trigonometric (non-linear) basis functions\n",
    "\n",
    "One common misconception regarding regression **under the *General* Linear model** (GLM) is that the basis functions are required to be linear. \n",
    "\n",
    "This is not the case. Indeed, the basis functions need not even be polynomial! They must be <em>linearly independent</em>, i.e. orthogonal. It is only the dependence on the model parameters, $\\mathbf{w}_{ML}$, that *must* be linear. \n",
    "\n",
    "An example of a **nonlinear** parameter model would be $y=\\exp(a)\\sin(x)$ where $a$ is the free parameter.\n",
    "\n",
    "Let's generate trigonometric data of the form $y = a + b\\sin(x) + c\\cos(x) + \\epsilon $ where again $\\epsilon$ is a random Gaussian component with zero mean. \n",
    "\n",
    "Here we chose basis functions $\\phi_0=1$, $\\phi_1(x)=sin(x)$ and $\\phi_2(x)=cos(x)$. If you're wondering if we're cheating a bit here, the answer is yes. In reality, we may not know ahead of time what the appropriate basis functions for the observed data should be. The appropriate choice may be suggested by the data, knowledge of the problem, and other machine learning techniques. It's like when we did probabilistic programming with `PyMC3`: You take the histogram of the data and you *guess* a probability distribution shape. This is similar: we *guess* basis functions. This is a *hyperparameter* of the model.\n",
    "\n",
    "In this example, our model will be $y=\\theta_0\\phi_0(x) + \\theta_1\\phi_1(x) + + \\theta_2\\phi_2(x)$, where presumably the solution should yield $\\theta_0 \\approx a$, $\\theta_1 \\approx b$ and $\\theta_2 \\approx c$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# in order to compare between examples, set a seed in random\n",
    "seed = 123456789\n",
    "np.random.seed(seed)\n",
    "\n",
    "def y(x,a,b,c,mu=0,sigma=1): \n",
    "    return a + b*math.sin(x) + c*math.cos(x) + np.random.normal(mu,sigma,1)[0]\n",
    "\n",
    "# training data, with N data points\n",
    "N = 101\n",
    "M = 3\n",
    "t = np.empty(N)\n",
    "domain = np.empty(N)\n",
    "domain_bound = 4.0*math.pi/N\n",
    "\n",
    "for i in range(N): \n",
    "    domain[i] = i * domain_bound\n",
    "for i in range (N): \n",
    "    t[i] = y(x=domain[i],a=1.85,b=0.57,c=4.37)\n",
    "    \n",
    "# design matrix, phi, N X M\n",
    "c1 = [math.sin(x) for x in domain]\n",
    "c2 = [math.cos(x) for x in domain]\n",
    "phi = np.array([np.ones(N),c1,c2]).T\n",
    "\n",
    "# find the solution. In this case case phi.T X phi is invertible so do the folloing:\n",
    "temp1 = np.linalg.inv(np.dot(phi.T,phi)) #inverse of phi.T X phi\n",
    "temp2 = np.dot(temp1, phi.T)\n",
    "w1 = np.dot(temp2,t) #solution\n",
    "\n",
    "print ('w1=', w1)\n",
    "\n",
    "# assuming that phi.T X phi was not invertible we could find the pseudo inverse using the pinv function\n",
    "# we expect to obtain the same solution\n",
    "phi_pi = np.linalg.pinv(phi)\n",
    "w2 = np.dot(phi_pi,t)\n",
    "print ('w2=', w2)\n",
    "\n",
    "# compute the model predicted values for the training data domain\n",
    "predicted_t = [w2[0]+w2[1]*math.sin(x)+w2[2]*math.cos(x) for x in domain]\n",
    "plt.plot(domain,t)\n",
    "plt.plot(domain, predicted_t)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stochastic Gradient Descent (SGD)\n",
    "\n",
    "In cases where the training data set is *very large* or data is received *in a stream*, a direct solution using the normal equations may not be possible, just like solving google's silver surfer equation *exactly*, *analytically*, is not possible and so we use the Power method involving knowledge of the dominant eigenvector (that its associated eigenvalue is 1).\n",
    "\n",
    "And so many times the only **tractable approach** is the so-called [stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) (SGD) algorithm, which is the basis of the [Loss](https://en.wikipedia.org/wiki/Loss_function) function of most artificial neural network models. \n",
    "\n",
    "If the total error function, TE, is the sum of a given error function, $E$, evaluated at each of the $N$ training inputs, $\\text{TE} = \\sum_{i=1}^N E(\\mathbf{x}_i)$ then the stochastic gradient descent algorithm is\n",
    "\n",
    "$$\\mathbf{w}^{\\tau + 1} = \\mathbf{w}^\\tau - \\eta \\bigtriangledown E_\\tau$$\n",
    "\n",
    "where ${\\tau}$ is the iteration number and $\\eta$ is a learning rate parameter. \n",
    "\n",
    "For this type of total error function, the order of evaluation does not change the result. If the error function is the sum-of-squares function, then the algorithm is\n",
    "\n",
    "$$\\mathbf{w}^{\\tau + 1} = \\mathbf{w}^\\tau + \\eta \\left(t_n - \\mathbf{w}^{(\\tau)T}\\phi_n\\right)\\phi_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Repeat example 2 with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#in order to compare between examples, set a seed in random\n",
    "seed = 123456789\n",
    "np.random.seed(seed)\n",
    "\n",
    "def y(x,a,b,c,mu=0,sigma=1): \n",
    "    return a + b*math.sin(x) + c*math.cos(x) + np.random.normal(mu,sigma,1)[0]\n",
    "\n",
    "N = 101\n",
    "M = 3\n",
    "w = np.zeros((M,1))\n",
    "phi = np.empty((M,1))\n",
    "eta = 0.25\n",
    "\n",
    "# create arrays to store the values as they are generated so they can be plotted at the end\n",
    "x = np.empty(N)\n",
    "t = np.empty(N)\n",
    "domain_bound = 4.0*math.pi/N\n",
    "for i in range(N):\n",
    "    x[i] = i * domain_bound\n",
    "    t[i] = y(x[i], a=1.85, b=0.57, c=4.37)\n",
    "    phi = np.array([[1], [math.sin(x[i])], [math.cos(x[i])]]) \n",
    "    w = w + eta*(t[i] - np.dot(w.T,phi))*phi #the learning model\n",
    "\n",
    "print(w.T)\n",
    "\n",
    "# compute the model predicted values for the training data domain\n",
    "predicted_t = [w[0] + w[1]*math.sin(item) + w[2]*math.cos(item) for item in x]\n",
    "plt.plot(x,t)\n",
    "plt.plot(x,predicted_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Over and Under Fitting\n",
    "\n",
    "The biggest issue in machine learning is over-fitting to the data, so that the model fits the data *exactly* and predicts new data *badly*. The technique used to counter this effect is called **regularization**.\n",
    "\n",
    "The general total error function <em>with a regularization term</em> is given by\n",
    "\n",
    "$$E_D(\\mathbf{w}) + \\lambda E_W(\\mathbf{w})$$\n",
    "\n",
    "where $\\lambda$ is the regularization coefficient and $E_W$ is the regularization term. \n",
    "\n",
    "A commonly used regularization term is the sum-of-squares of the model parameter elements\n",
    "\n",
    "$$E_W(\\mathbf{w}) = \\frac1{2}\\mathbf{w}^T\\mathbf{w}$$\n",
    "    \n",
    "known as the <em>weight decay</em> regularizer. The goal here is to reduce the **variance** of our model: The less our model ***wiggles***, the less it conforms to detail, so the more general it can be. This regularization terms leads to the optimal solution, assuming a linear regression model with Gaussian noise on the training data, of\n",
    "\n",
    "$$\\mathbf{w} = \\left(\\lambda \\mathbf{I} + \\mathbf{\\Phi}^T \\mathbf{\\Phi}\\right)^{-1} \\mathbf{\\Phi}^T\\mathbf{t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Overfitting\n",
    "\n",
    "In this example, we use the same training data as Example 1, except that here, the model is erroneously chosen to be a **7th order polynomial**!\n",
    "\n",
    "This example is somewhat contrived, but it illustrates the point that an overfit model can be corrected to some extent using regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#in order to compare between examples, set a seed in random\n",
    "seed = 123456789\n",
    "np.random.seed(seed)\n",
    "\n",
    "def y(x,m,b,mu=0,sigma=1): \n",
    "    return m*x + b + np.random.normal(mu,sigma,1)[0]\n",
    "\n",
    "def el_pow(x,pow):\n",
    "    temp = x\n",
    "    for i in range(pow-1):\n",
    "        temp = temp * x\n",
    "    return temp\n",
    "\n",
    "def prediction(params, x):\n",
    "    pred = 0\n",
    "    for i in range(len(params)):\n",
    "        pred += params[i] * math.pow(x,i)\n",
    "    return pred\n",
    "\n",
    "# training data, with N data points\n",
    "N = 101\n",
    "M = 8\n",
    "t = np.empty(N)\n",
    "domain = np.empty(N)\n",
    "domain_bound = 1.0/N\n",
    "\n",
    "for i in range(N): \n",
    "    domain[i] = i*domain_bound\n",
    "for i in range(N): \n",
    "    t[i] = y(x=domain[i], m=4.89,b=0.57)\n",
    "\n",
    "# find the solution without using regularization\n",
    "# design matrix, phi, N X M\n",
    "phi = np.array([np.ones(N),domain, el_pow(domain,2), el_pow(domain,3), el_pow(domain,4), el_pow(domain,5), el_pow(domain,6), el_pow(domain,7)]).T\n",
    "temp1 = np.linalg.inv(np.dot(phi.T,phi)) #inverse of phi.T X phi\n",
    "temp2 = np.dot(temp1, phi.T)\n",
    "w1 = np.dot(temp2, t) #solution\n",
    "\n",
    "print ('w1=',w1)\n",
    "predicted_t = [prediction(w1,x) for x in domain]\n",
    "\n",
    "#find the regularized solution\n",
    "lam = 0.1\n",
    "temp1 = np.linalg.inv(lam * np.eye(M) + np.dot(phi.T,phi))\n",
    "temp2 = np.dot(temp1, phi.T)\n",
    "w2 = np.dot(temp2, t)\n",
    "print ('w2=',w2)\n",
    "predicted_t_reg = [prediction(w2,x) for x in domain]\n",
    "\n",
    "#add some plots\n",
    "plt.plot(domain,t)\n",
    "plt.plot(domain,predicted_t)\n",
    "plt.plot(domain,predicted_t_reg)\n",
    "plt.legend((\"training\",\"un-regularized\",\"regularized\"), loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><font color=\"grey\">A bit of math</font></div>\n",
    "\n",
    "## 7. Bayesian Estimation\n",
    "\n",
    "Here we consider a fully **Bayesian approach** to the regression problem. First note, that our fundamental **model** assumptions still hold. Namely, we assume that the observation we are trying to predict is modeled by\n",
    "\n",
    "$$t = y(\\mathbf{x},\\mathbf{w}) + \\epsilon$$\n",
    "\n",
    "where $\\epsilon$ is a Gaussian distributed noise component. \n",
    "\n",
    "Additionally, the assumption of a linear dependence on the model parameters, $\\mathbf{w}$ also still holds:\n",
    "\n",
    "$$y(\\mathbf{x},\\mathbf{w}) = \\sum_{j=0}^{M-1} w_j\\phi_j(\\mathbf{x}) = \\mathbf{w}^T\\mathbf{\\phi}(\\mathbf{x})$$\n",
    "\n",
    "Recall that the Bayesian approach implies that the *best* model parameters, $\\mathbf{w}$, are those that maximize the **posterior** probability, which from Bayes' Theorem is given by:\n",
    "\n",
    "$$p(\\mathbf{w}|\\mathbf{t}) = \\frac{p(\\mathbf{t}|\\mathbf{w})p(\\mathbf{w})}{p(\\mathbf{t})}$$\n",
    "\n",
    "### Prior Model\n",
    "The first step in formulating a Bayesian model is to construct a model for the *prior* probability model, $p(\\mathbf{w})$. \n",
    "\n",
    "In general, any probability distribution model could be chosen to \n",
    "model the prior. The appropriate choice is dependent on different factors including prior knowledge of the problem and mathematical convenience. Often, the prior is chosen to be the [conjugate prior](https://en.wikipedia.org/wiki/Conjugate_prior) of the \n",
    "likelihood function. This is a choice of mathematical convenience because it implies that the *posterior* can be derived analytically. It is often a reasonable choice, as is this case here for the problem of linear regression. \n",
    "\n",
    "Thus, given the Gaussian distribution used for the likelihood function above, we assume a Gaussian distribution for our *prior* of the form:\n",
    "\n",
    "$$p(\\mathbf{w}) = \\mathcal{N}(\\mathbf{w}\\;|\\;\\mathbf{m}_0, \\; \\mathbf{S}_0)$$\n",
    "\n",
    "where $\\mathbf{m}_0$ is the prior **mean** and $\\mathbf{S}_0$ is the prior **covariance**. \n",
    "\n",
    "We will *assume* $\\mathbf{m}_0 = 0$ and an infinitely broad prior so that $\\mathbf{S}_0=\\alpha^{-1}\\mathbf{I}$ where $\\alpha$ is a precision parameter that we will have to choose. Given these choices of *prior* and *likelihood* functions the *posterior* probability is given by\n",
    "\n",
    "$$p(\\mathbf{w}|\\mathbf{t}) = \\mathcal{N}\\left(\\mathbf{w}\\;|\\;\\mathbf{m}_N, \\;\\mathbf{S}_N\\right)$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\mathbf{m}_N = \\beta \\; \\mathbf{S}_N \\mathbf{\\Phi}^T \\mathbf{t}$$\n",
    "\n",
    "$$\\mathbf{S}_N^{-1} = \\alpha \\;\\mathbf{I} + \\beta \\; \\mathbf{\\Phi}^T\\mathbf{\\Phi}$$\n",
    "\n",
    "where $\\beta = 1/\\sigma^2$ is the inverse variance of the random noise component associated with the target variable, \n",
    "$t = y(\\mathbf{x},\\mathbf{w}) + \\mathcal{N}(0, \\sigma^2)$. \n",
    "\n",
    "Finally, the log of the *posterior* is seen to be the sum of the log likelihood **and** the log of the prior:\n",
    "\n",
    "$$\\ln p(\\mathbf{w}\\;|\\;\\mathbf{t}) = -\\frac{\\beta}{2}\\sum_{n=1}^N\\left[{t_n - \\mathbf{w}^T \\phi(\\mathbf{x}_n)}\\right]^2 - \\frac{\\alpha}{2}\\mathbf{w}^T\\mathbf{w} + constant$$\n",
    "\n",
    "**NOTE:** <font color=\"red\">Maximizing the posterior function with respect to $\\mathbf{w}$ __under the assumption of Gaussian noise and a Gaussian prior__ is equivalent to the least-squares error solution \n",
    "with the addition of a regulariztion term $\\lambda = \\alpha/\\beta$.</font>\n",
    "\n",
    "Rather than find a point estimate for $\\mathbf{w}$ by maximizing the posterior and thereby make point predictions for the target variable $t$, it is more instructive to use the posterior to formulate a *predictive distribution* for $t$. For **our model assumptions** this is given by\n",
    "\n",
    "$$p(t\\;|\\;\\mathbf{t},\\alpha,\\beta) = \\int p(t\\;|\\;\\mathbf{w},\\beta) \\; p(\\mathbf{w}\\;|\\;\\mathbf{t}, \\alpha, \\beta) \\;d\\mathbf{w} = \\mathcal{N}(t\\;|\\;\\mathbf{m}_N^T\\phi(\\mathbf{x}), \\frac{1}{\\beta} + \\phi(\\mathbf{x})^T \\mathbf{S}_N \\phi(\\mathbf{x}))$$\n",
    "\n",
    "where a point estimate of $t$ is given my the mean $\\mu = \\mathbf{m}_N^T\\phi(\\mathbf{x})$ and an estimate of the uncertainty is given by the standard deviation \n",
    "$\\sigma_N^2(\\mathbf{x}) = \\frac{1}{\\beta} + \\phi(\\mathbf{x})^T \\mathbf{S}_N \\phi(\\mathbf{x} )$\n",
    "\n",
    "There is one final issue with completing the Bayesian model, namely the determination of $\\alpha$ and $\\beta$. This can be done in a fully Bayesian manner by developing prior models but this tends to make the equations intractible. Instead the so called *evidence function* approach is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Bayesian estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# in order to compare between examples, set a seed in random\n",
    "seed = 123456789\n",
    "np.random.seed(seed)\n",
    "\n",
    "alpha = 0.4\n",
    "beta = 5.0\n",
    "\n",
    "def y(x,coefs, mu=0, sigma=1.0/beta): \n",
    "    ans = 0\n",
    "    for i in range(len(coefs)): \n",
    "        ans += coefs[i]*math.pow(x,i)\n",
    "    return ans + np.random.normal(mu,sigma,1)[0]\n",
    "    \n",
    "# training data, with N = 101 data points\n",
    "N = 101\n",
    "M = 4\n",
    "t = np.empty(N)\n",
    "domain = np.empty(N)\n",
    "domain_bound = 3.0/N\n",
    "\n",
    "for i in range(N): \n",
    "    domain[i] = i*domain_bound\n",
    "for i in range(N): \n",
    "    t[i] = y(x=domain[i],coefs=[1.75, 0.25, -1.0])\n",
    "\n",
    "# Let's assume that we want to fit a 3rd order polynomial to the data even though we know its a second order\n",
    "# polynomial. Given the Bayesian approach, we should see that unecessary terms are damped out. We have \n",
    "# y = phi_0 + phi_1 * x + phi_2 x^2 + phi_3 x^4\n",
    "\n",
    "# design matrix, phi, N X M where N = 101 and M = 4\n",
    "d2 = domain * domain\n",
    "phi = np.array([np.ones(N),domain, d2, d2 * domain]).T\n",
    "alphaI = alpha * np.eye(M)\n",
    "SN = np.linalg.inv(alphaI + beta * np.dot(phi.T,phi)) #posterior variance\n",
    "mN = beta * np.dot(np.dot(SN, phi.T), t)\n",
    "point_estimates = [np.dot(mN, phi[i]) for i in range(N)]\n",
    "uncertain_t = [1.0/beta + np.dot(np.dot(phi[i].T, SN), phi[i]) for i in range(N)]\n",
    "plt.plot(domain,t)\n",
    "plt.errorbar(domain,point_estimates, uncertain_t, ecolor = \"red\")\n",
    "plt.legend(('training','Bayes'),loc='lower left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Linear Regression Conclusion\n",
    "\n",
    "Why did we spend so much time on linear regression? Because generative ML ***is*** regression: Building a model of the data so we can throw away the data and keep the model to predict future action, and **linear** is the simplest kind of regression. Later one we'll see that more powerful models are often but a superposition of linear models.\n",
    "\n",
    "The neat part though is to realize that *this* is what your brain does when you try to find a new girlfriend: You remember all your *failed attempts* and you build a mental model of what it takes to find a nice girlfriend and *not* repeat the same mistakes.\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src=\"ipynb.images/nu-chick.png\" width=500 />\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><font color=\"grey\">a bit of math</font></div>\n",
    "\n",
    "# 9. Classification\n",
    "\n",
    "The mathematics of classification is a bit tough because it usually involves an **activation function** to help classify, same kind of activation function involved in neural networks, and that activation function is generally non-linear. So we'll cut straight to the chase and showcase an example using the **logistic function**.\n",
    "\n",
    "Classification is where, given an input vector $\\mathbf{x}$, you need to determine $p(C_k\\;|\\;\\mathbf{x})$ where $k\\in {1\\ldots K}$ and $C_k$ is a discrete class label, in other words the elements $y_i = p(C_i\\;|\\;\\phi(\\mathbf{x}))$ i.e. the probability that the correct class label is $C_i$ given the input vector $\\mathbf{x}$. The function $\\phi$ is known as the **activation function** and its inverse is known as the **link function**. $\\phi$ is often nonlinear.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The general case of discriminative Models\n",
    "\n",
    "Probablistic discriminative models assume a generalized *linear* model:\n",
    "\n",
    "$$y(\\phi(\\mathbf{x})) = f(\\mathbf{w}^T\\phi(\\mathbf{x}))$$\n",
    "\n",
    "\n",
    "#### The special case of Logistic Regression\n",
    "\n",
    "We will consider Logistic Regression for the case of **two classes**, assuming a model for the class posterior probabilities, $p(C_k\\;|\\;\\phi(\\mathbf{x}))$, in the form of the logistic sigmoid for $k = 1, 2$:\n",
    "\n",
    "$$p(C_1\\;|\\;\\phi) = f(a) = \\sigma(\\mathbf{w}^T\\phi)$$\n",
    "\n",
    "with \n",
    "\n",
    "$$p(C_2\\;|\\;\\phi) = 1 - p(C_1\\;|\\;\\phi)$$\n",
    "\n",
    "We apply maximum likelihood to obtain the model parameters. Assume that our training set, $\\mathbf{t}$, is of the form $\\\\{\\phi_n,t_n\\\\}$ where $\\phi_n=\\phi(\\mathbf{x}_n)$, $t_n \\in \\{0,1\\}$,\n",
    "and $n=1\\ldots N$. The likelihood function of the training data is then\n",
    "\n",
    "$$p(\\mathbf{t}|\\mathbf{w}) = \\prod_{n=1}^N \\sigma(\\mathbf{w}^T \\phi(\\mathbf{x}_n))^{t_n} (1 - \\sigma(\\mathbf{w}^T \\phi(\\mathbf{x}_n)))^{1-t_n}$$\n",
    "\n",
    "Defining the error function $E(\\mathbf{w})$, as the negative of the log-likelihood function, and taking the gradient with respect to $\\mathbf{w}$, we obtain\n",
    "\n",
    "$$\\bigtriangledown E(\\mathbf{w}) = \\sum_{n=1}^N \\left[\\sigma(\\mathbf{w}^T \\phi(\\mathbf{x}_n)) - t_n\\right] \\phi(\\mathbf{x}_n)$$\n",
    "\n",
    "Superficially, this error function looks the same as that obtained for **linear** regression under the assumption of a Gaussian noise model which had a closed form solution. However, the nonlinearity of the *sigmoid* function, $\\sigma(\\mathbf{w}^T \\phi(\\mathbf{x}_n))$ prevents a closed form solution in the **logistic** regression problem. We therefore must apply an iterative method to obtain a numerical solution for the parameters, $\\mathbf{w}$. Let's\n",
    "consider the *Newton-Raphson* method for which minimizing the error function takes the form\n",
    "\n",
    "$$\\mathbf{w}^{\\tau+1} = \\mathbf{w}^{\\tau} - \\mathbf{H}^{-1}\\bigtriangledown E(\\mathbf{w})$$\n",
    "\n",
    "where $\\mathbf{H}$ is the *Hessian* matrix composed of the second derivatives of the error function\n",
    "\n",
    "$$\\mathbf{H} = \\bigtriangledown \\bigtriangledown E(\\mathbf{w}) = \\Phi^T \\mathbf{R} \\Phi$$\n",
    "\n",
    "where $\\Phi$ is the $N \\times M$ design matrix whos $n^{th}$ row is given by $\\phi(\\mathbf{x_n})^T$ and $\\mathbf{R}$ is an $N \\times N$ diagonal matrix with elements $R_{n,n} = \\sigma(\\mathbf{w}^T \\phi(\\mathbf{x}_n)) \\left[1-\\sigma(\\mathbf{w}^T \\phi(\\mathbf{x}_n))\\right]$. This can be reduced to a form equivalent to that of localy weighted linear *regression* as follows\n",
    "\n",
    "$$\\mathbf{w}^{\\tau+1} = \\left( \\Phi^T \\mathbf{R} \\Phi \\right)^{-1} \\Phi^T \\mathbf{R} \\mathbf{z}$$\n",
    "\n",
    "where $\\mathbf{z}$ is an $N$ dimensional vector defined by\n",
    "\n",
    "$$\\mathbf{z} = \\Phi \\mathbf{w}^{\\tau} - \\mathbf{R}^{-1}(\\mathbf{y} - \\mathbf{t})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Classification using a kernel method\n",
    "\n",
    "Consider an example with two classes and 2D input, $\\mathbf{x_n} = (x_n^{(1)},x_n^{(2)})$. As an experiment, try to increase the number of training points, $N$. Eventually, the training points will overlap so that it will not be possible to completely seperate them with the transformation provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import reduce\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 123456789\n",
    "np.random.seed(seed)\n",
    "\n",
    "N = 100 #number of data points, SEE WHAT HAPPENS AS YOU INCREASE THIS TO SAY 200\n",
    "D = 2   #dimension of input vector\n",
    "t = np.zeros(N) #training set classifications\n",
    "X = np.zeros((N,D)) #training data in input space\n",
    "sigma = .25\n",
    "mu0 = 0.0\n",
    "mu1 = 1.0\n",
    "\n",
    "# function for generating 2D class scatter plot\n",
    "def createScatter(X, t, ax):\n",
    "    C1x = []  \n",
    "    C1y = []\n",
    "    C2x = []\n",
    "    C2y = []\n",
    "    for i in range(len(t)):\n",
    "        if t[i] > 0: \n",
    "            C1x.append(X[i,0])\n",
    "            C1y.append(X[i,1])\n",
    "        else: \n",
    "            C2x.append(X[i,0])\n",
    "            C2y.append(X[i,1])\n",
    "    ax.scatter(C1x,C1y)\n",
    "    ax.scatter(C2x,C2y, color='r')\n",
    "    \n",
    "# Generate test data. (NOTE THIS IS NOT BASED ON A GENERATIVE APPROACH. \n",
    "# IN PRACTICE THIS DATA WOULD BE OBTAINED VIA OBSERVATION)\n",
    "# Pick a value from a uniform distribution [0,1). If it is less than 0.5, assign class 1 and pick x1,x2 from a normal\n",
    "# distribution(mu0,sigma) otherwise assign class 2 and pick x1,x2 from a normal distribution(mu1,sigma)\n",
    "for i in range(N):\n",
    "    #choose class to sample for\n",
    "    fac = 1\n",
    "    if np.random.rand() <= 0.5:\n",
    "        thismu = mu0\n",
    "        t[i] = 1\n",
    "    else: \n",
    "        thismu = mu1\n",
    "        t[i] = 0\n",
    "        if np.random.rand() < 0.5: fac = -1\n",
    "        \n",
    "    X[i,0] = fac * np.random.normal(thismu, sigma)\n",
    "    X[i,1] = fac * np.random.normal(thismu, sigma)\n",
    "    \n",
    "\n",
    "f, axarr = plt.subplots(1,3)\n",
    "f.subplots_adjust(right=2.5)\n",
    "f.text(0.75,0.975,'Fixed Input Transformation Yields Linear Class Boundary',horizontalalignment='center',verticalalignment='top')\n",
    "\n",
    "ax1 = axarr[0]\n",
    "ax1.set_xlabel('x1')\n",
    "ax1.set_ylabel('x2')\n",
    "createScatter(X,t,ax1)\n",
    "\n",
    "# The training data does not have a linear boundary in the original input space. \n",
    "# So let's apply a tranformation, phi to try to make it linearly seperable.\n",
    "# NOTE: This transformation is not the only one that works. For example try switching the values of MU1 and MU2. \n",
    "# The result will be a different mapping that is also linearly seperable. \n",
    "# This technique is known as a kernel method.\n",
    "def phi(x,mu,sigma):\n",
    "    detSigma = np.linalg.det(sigma)\n",
    "    fac = math.pow(2*math.pi, len(mu)/2.0) * math.sqrt(detSigma)\n",
    "    arg = -0.5 * np.dot((x-mu).T, np.dot(np.linalg.inv(sigma), x-mu) )\n",
    "    return math.exp(arg) / fac\n",
    "    \n",
    "phiX = np.zeros((N,D))\n",
    "MU1 = np.ones(D)*mu0\n",
    "MU2 = np.ones(D)*mu1\n",
    "SIGMA = np.diag(np.ones(D))*sigma\n",
    "for i in range(N):\n",
    "    phiX[i,0] = phi(x=X[i,:], mu=MU2, sigma=SIGMA)\n",
    "    phiX[i,1] = phi(x=X[i,:], mu=MU1, sigma=SIGMA)\n",
    "    \n",
    "ax2 = axarr[1]\n",
    "ax2.set_xlabel('phi1(x)')\n",
    "ax2.set_ylabel('phi2(x)')\n",
    "createScatter(phiX, t, ax2)\n",
    "\n",
    "# Now lets apply machine learning to determine the boundary. We will assume M = 3, i.e. that there are 3 free parameters \n",
    "# that is w = [w0, w1, w2]^T and phi_n = [1, phiX[0], phiX[1]]\n",
    "M = 3\n",
    "Phi = np.ones((N,M))\n",
    "Phi[:,1] = phiX[:,0]\n",
    "Phi[:,2] = phiX[:,1]\n",
    "w = np.zeros(M)\n",
    "R = np.zeros((N,N))\n",
    "y = np.zeros(N)\n",
    "\n",
    "def sigmoid(a):\n",
    "   return 1.0 / (1.0 + math.exp(-a))\n",
    "\n",
    "def totalErr(y,t):\n",
    "    e = 0.0\n",
    "    for i in range(len(y)):\n",
    "        if t[i] > 0:\n",
    "            e += math.log(y[i])\n",
    "        else:\n",
    "            e += math.log(1.0 - y[i])\n",
    "    return -e\n",
    "\n",
    "# start Newton-Raphson. As a stopping criteria we will use a tolerance on the change in the error function \n",
    "# and a max number of iterations\n",
    "max_its = 100\n",
    "tol = 1e-2\n",
    "w0 = [w[0]] \n",
    "w1 = [w[1]]\n",
    "w2 = [w[2]]\n",
    "err = []\n",
    "error_delta = 1 + tol\n",
    "current_error = 0\n",
    "idx = 0\n",
    "\n",
    "while math.fabs(error_delta)>tol and idx < max_its:\n",
    "    #update y & R\n",
    "    for i in range(N): \n",
    "        zipped = zip(w, Phi[i,:])\n",
    "        y[i] = sigmoid(reduce(lambda accum, Z: accum + Z[0]*Z[1], zipped, 0))\n",
    "        R[i,i] = y[i] - y[i]*y[i]\n",
    "        \n",
    "    #update w\n",
    "    z = np.dot(Phi,w) - np.dot(np.linalg.pinv(R),y-t)\n",
    "    temp = np.linalg.pinv(np.dot(np.dot(Phi.T,R),Phi))\n",
    "    temp2 = np.dot(np.dot(temp, Phi.T),R)\n",
    "    w = np.dot(temp2, z)\n",
    "    w0.append(w[0])\n",
    "    w1.append(w[1])\n",
    "    w2.append(w[2])\n",
    "    idx += 1\n",
    "    temp = totalErr(y,t)\n",
    "    error_delta = current_error - temp\n",
    "    current_error = temp\n",
    "    err.append(error_delta)\n",
    "    \n",
    "print ('The total number of iterations was {0}'.format(idx))\n",
    "print ('The total error was {0}'.format(current_error))\n",
    "print ('The final change in error was {0}'.format(error_delta))\n",
    "print ('The final parameters were {0}'.format(w))\n",
    "    \n",
    "# our decision boundary is now formed by the line where sigma(a) = 0.5, i.e. where a = 0, which for this example is \n",
    "# where phi2 = -(w1/w2)phi1, i.e. where w * phi = .5\n",
    "bdryx = (0,1)\n",
    "bdryy = (-(w[0]+w[1]*bdryx[0])/w[2], -(w[0]+w[1]*bdryx[1])/w[2])\n",
    "ax2.plot(bdryx, bdryy)\n",
    "\n",
    "ax3 = axarr[2]\n",
    "ax3.plot(w0, color = 'blue')\n",
    "ax3.plot(w1, color = 'red')\n",
    "ax3.plot(w2, color = 'green')\n",
    "ax3.plot(err, color = 'black')\n",
    "ax3.legend((\"w0\",\"w1\",\"w2\", \"error delta\"), loc='upper left')\n",
    "ax3.set_xlabel('Newton-Raphson Iteration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first figure on the left represents the original data in signals x1 and x2. Note how it is not linearly separable because you cannot draw straight lines that separate the blue dots for the red dots. So we need to appy a kernel function to the data to map them to different regions in the plane so that they can be separated by a line, which is what the middle graph depicts. The figure on the right shows how the three parameters in the model change with Newton Raphson iterations. The growth of the 3rd parameter w2 is *scary*. Will it continue growing without bound? If so, we have a problem in our model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Artificial Neural Networks\n",
    "\n",
    "Neural networks are an approach to machine learning that attempts to deal with the problem of large data dimensionality. The neural network approach uses a fixed number of basis functions (in contrast\n",
    "to methods such as support vector machines that attempt to adapt the number of basis functions themselves parameterized by the model parameters). \n",
    "\n",
    "However, there is a significant departure from linear regression and logistic regression methods where the models consisted of linear combinations of fixed basis functions, $\\phi(\\mathbf{x})$, that depended only on the input vector, $\\mathbf{x}$. \n",
    "\n",
    "In neural networks, basis functions can now depend on both model parameters *and* the input vector and thus take the form $\\phi(\\mathbf{x} | \\mathbf{w})$. \n",
    "\n",
    "It is simpler to start with **feed-forward** neural networks (as opposed to **recursive neural networks**). One can envision a neural network as a series of layers where each layer has some number of nodes and each node is a function. \n",
    "\n",
    "> **NEURAL NETWORKS**: Each layer represents a single linear regression model!\n",
    "\n",
    "The nodes are connected to each other through inputs from, and outputs passed to, other nodes. A *feed-forward* network is one in which these connections do not form any directed cycles. See [here](http://en.wikipedia.org/wiki/Feedforward_neural_network) for more detail.\n",
    "\n",
    "As a matter of convention, we always refer the model as aN $N$ layer model where $N$ is the number of layers for which adaptive parameters, $\\mathbf{w}$, must be determined. Thus for a model consisting of an input layer, one hidden layer, and an output layer, we consider $N$ to be 2 since parameters are determined only for the hidden and output layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-forward Network Functions\n",
    "\n",
    "We will consider a basic two layer neural network model, i.e. a model that maps inputs to a hidden layer and then to an output layer. We make **the following assumptions**:\n",
    "\n",
    "1. The final output will be a vector $Y$ with $K$ elements, $y_k$, where $y_k(\\mathbf{x},\\mathbf{w}) = p(C_1|\\mathbf{x})$ is the probability that node $k$ is in class $C_1$ and $p(C_2|\\mathbf{x}) = 1-p(C_1|\\mathbf{x})$\n",
    "2. The activation function at a given layer is an arbitrary nonlinear function of a linear combination of the inputs and parameters for that layer\n",
    "3. The network is fully connected, i.e. every node at the input layer is connected to every node in the hidden layer and every node in the hidden layer is connected to every node in the output layer\n",
    "4. A bias parameter is included at the hidden and output layers\n",
    "\n",
    "Working from the input layer toward the output layer, we can build this model as follows:\n",
    "\n",
    "### Input Layer\n",
    "Assume we have an input vector $\\mathbf{x} \\in \\Re^D$. Then the input layer consists of $D+1$ nodes where the value of the $i^{th}$ node for $i=0\\ldots D$, is 0 if $i=0$ and $x_i$, i.e. the $i^{th}$ value of $\\mathbf{x}$, otherwise.\n",
    "\n",
    "### Hidden Layer\n",
    "At the hidden layer we construct $M$ nodes where the value of $M$ depends on the specifics of the particular modelling problem. For each node, we define a *unit activation*, $a_m$, for $m=1\\ldots M$ as\n",
    "\n",
    "$$a_m = \\sum_{i=0}^D w_{ji}^{(1)}x_i$$\n",
    "\n",
    "where the $(1)$ superscript indicates this weight is for the hidden layer. The output from each node, $z_m$, is then given by the value of a *fixed nonlinear function* $h$, known as the *activation function*, acting on the unit activation:\n",
    "\n",
    "$$z_m = h(a_m) = h \\left( \\sum_{i=0}^D w_{mi}^{(1)}x_i \\right)$$\n",
    "\n",
    "Notice that $h$ is the same function for all nodes.\n",
    "\n",
    "### Output Layer\n",
    "The process at the output layer is essentially the same as at the hidden layer. We construct $K$ nodes, where again the value of $K$ depends on the specific modeling problem. For each node, we again define a *unit activation*, $a_k$, for $k=1 \\ldots K$ by\n",
    "\n",
    "$$a_k = \\sum_{m=0}^M w_{km}^{(2)} z_m$$\n",
    "\n",
    "We again apply a nonlinear activation function, say $y$, to produce the output\n",
    "\n",
    "$$y_k = y(a_k)$$\n",
    "\n",
    "Thus, the entire model can be summarized as a $K$ dimensional output vector $Y \\in \\Re^K$ where each element $y_k$ by\n",
    "\n",
    "$$y_k(\\mathbf{x},\\mathbf{w}) = y \\left( \\sum_{m=0}^M w_{km}^{(2)} h \\left( \\sum_{i=0}^D w_{mi}^{(1)}x_i \\right) \\right)$$\n",
    "\n",
    "### Generalizations\n",
    "There are a wide variety of generalizations possible for this model. Some of the more important ones for practical applications include\n",
    "\n",
    "* Addition of **more hidden layers**\n",
    "* Inclusion of **skip-layer** connections, e.g. a connection from an input node directly to an output node\n",
    "* **Sparse network**, i.e. not a *fully* connected network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Training\n",
    "\n",
    "Here we will consider how to determine the network model parameters. We will use a *maximum likelihood estimation* approach. \n",
    "\n",
    "The likelihood function for the network is dependent on the type of problem the network models. Of particular importance is the number and type of values generated at the output layer. We consider two cases below.\n",
    "\n",
    "### Regression Single Gaussian Target\n",
    "\n",
    "*Assume* that our target variable (label) *t* is Gaussian distributed with an $\\mathbf{x}$ dependent mean $\\mu(\\mathbf{x})$ and constant variance $\\sigma^2 = 1/\\beta$. Our network model is designed to estimate the unknown function for the mean, i.e. $y(\\mathbf{x},\\mathbf{w}) \\approx \\mu(\\mathbf{x})$ so that the distribution for the target value, *t*, is modeled by\n",
    "\n",
    "$$p(t\\;|\\;\\mathbf{x},\\mathbf{w}) = \\mathcal{N}(t\\;|\\;y(\\mathbf{x},\\mathbf{w}), \\;1/\\beta) = = \\mathcal{N}(t@y(\\mathbf{x},\\mathbf{w}), \\;1/\\beta)$$\n",
    "\n",
    "where $\\mathcal{N}(\\mu,\\sigma^2)$ is the normal distribution with mean $\\mu$ and variance $\\sigma^2$. *Assume* the output layer activation function is the identity, i.e. the output is simply the unit activations, and that we have $N$ independent observations $\\mathbf{X}={\\mathbf{x}_1, \\ldots, \\mathbf{x}_2 }$ and target (label) values $\\mathbf{t} = {t_1, \\ldots, t_2}$. The likelihood function is\n",
    "\n",
    "$$p(\\mathbf{t}\\;|\\;\\mathbf{X},\\mathbf{w}, \\beta) = \\prod_{n=1}^N p(t_n\\;|\\;\\mathbf{x}_n, \\mathbf{w}, \\beta)$$\n",
    "\n",
    "The **total error function** is defined as the negative logarithm of the likelihood function given by\n",
    "\n",
    "$$\\frac {\\beta}{2} \\sum_{n=1}^N \\{y(\\mathbf{x}_n,\\mathbf{w}) - t_n \\}^2 - \\frac{N}{2} \\ln(\\beta) + \\frac{N}{2} \\ln (2\\pi)$$\n",
    "\n",
    "The parameter estimates, $\\mathbf{w}^{(ML)}$ (ML indicates maximum likelihood) are found by maximizing the equivalent sum-of-squares error function\n",
    "\n",
    "$$E(\\mathbf{w}) = \\frac{1}{2} \\sum_{n=1}^N \\{y(\\mathbf{x}_n,\\mathbf{w}) - t_n \\}^2$$\n",
    "\n",
    "Note, due to the nonlinearity of the network model, $E(\\mathbf{w})$ is not necessarily convex, and thus may have *local minima* and hence it is not possible to know for sure that the global minimum has been obtained.  The model parameter, $\\beta$ is found by first finding $\\mathbf{w}_{ML}$ and then solving\n",
    "\n",
    "$$\\frac{1}{\\beta_{ML}} = \\frac{1}{N}\\sum_{n=1}^N \\{ y(\\mathbf{x}_n,\\mathbf{w}^{(ML)}) - t_n \\}^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Multiple Gaussian Targets\n",
    "\n",
    "Now *assume* that we have $K$ Gaussian distributed target variables (labels), $t_1, \\ldots, t_K$, each with a mean that is independently conditional on $\\mathbf{x}$, i.e. the mean of $t_k$ is defined by some function $\\mu_k(\\mathbf{x})$. \n",
    "\n",
    "Also assume that all $K$ variables share the same variance, $\\sigma^2=1/\\beta$. Assuming the network output layer has $K$ nodes where $y_k(\\mathbf{x},\\mathbf{w}) \\approx \\mu_k(\\mathbf{x})$ and letting $\\mathbf{y}(\\mathbf{x},\\mathbf{w}) = y_1(\\mathbf{x},\\mathbf{w}), \\ldots, y_K(\\mathbf{x},\\mathbf{w})$, and that we again have $N$ training target values $\\mathbf{t}$ ($\\mathbf{t}$ is a $K \\times N$ matrix of the training values), the conditional distribution of the target training values is given by\n",
    "\n",
    "$$p(\\mathbf{t}|\\mathbf{x},\\mathbf{w}) = \\mathcal{N}(\\mathbf{t} | \\mathbf{y}(\\mathbf{x},\\mathbf{w}), \\beta^{-1} \\mathbf{I})$$\n",
    "\n",
    "The parameter estimates, $\\mathbf{w}^{(ML)}$ are again found by minimizing the sum-of-squares error function, $E(\\mathbf{w})$, and the estimate for $\\beta$ is found from\n",
    "\n",
    "$$\\frac{1}{\\beta_{ML}} = \\frac{1}{NK}\\sum_{n=1}^N ||y(\\mathbf{x}_n,\\mathbf{w}^{(ML)}) - t_n ||^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Backpropagation\n",
    "\n",
    "Most training algorithms involve a two-step procedure for minimizing the model parameter dependent error function\n",
    "\n",
    "1. Evaluate the derivatives of the error function with respect to the parameters\n",
    "2. Use the derivatives to iterate the values of the parameters\n",
    "\n",
    "**Error backpropagation** provides an efficient way to evaluate a feed-forward neural network's error function. *Note* that this only satisfies step 1 above. It is still necessary to choose an optimization technique in order to use the derivative information provided by error backpropagation to update the parameter estimates as indicated by step 2. \n",
    "\n",
    "The results presented here are applicable to \n",
    "\n",
    "1. An **arbitary** feed-forward network toplogy\n",
    "2. **Arbitrary** differentiable nonlinear activation functions\n",
    "\n",
    "The one *assumption* that is made is that the error function can be expressed as a *sum of terms*, one for each training data point, $t_n$ for $n \\in {1\\ldots N}$, so that\n",
    "\n",
    "$E(\\mathbf{w}) = \\sum_{n=1}^N E_n(\\mathbf{w},t_n)$\n",
    "\n",
    "For such error functions, the derivative of the error function with respect to $\\mathbf{w}$ takes the form\n",
    "\n",
    "$\\bigtriangledown E(\\mathbf{w}) = \\sum_{n=1}^N \\bigtriangledown E_n(\\mathbf{w},t_n)$\n",
    "\n",
    "Thus we need only consider the evaluation of $\\bigtriangledown E_n(\\mathbf{w},t_n)$ which may be used directly for sequential optimization techniques or summed over the training set for batch techniques (see next section). The error backpropagation method can be summarized as follows\n",
    "\n",
    "1. Given an input vector, $\\mathbf{x}_n$, forward-propagate through the network using \n",
    "    1. $a_j = \\sum_i w_{ji}z_i$\n",
    "    2. $z_j = h(a_j)$\n",
    "    \n",
    "    \n",
    "2. Evaluate $\\delta_k \\equiv \\frac{\\partial E_n} {\\partial a_k}$ for the output layer as\n",
    "    1. $\\delta_k = y_k - t_k$\n",
    "    \n",
    "    \n",
    "3. Backpropagate the $\\delta$'s to obtain $\\delta_j$ for each hidden unit in the network using\n",
    "    1. $\\delta_j = h'(a_j) \\sum_k w_{kj}\\delta_k$\n",
    "    \n",
    "    \n",
    "4. Evaluate the derivatives using \n",
    "    1. $\\frac{\\partial E_n} {\\partial w_{ji}} = \\delta_j z_i$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Optimization\n",
    "\n",
    "Given the neural network error function derivative estimate provided by *error backpropagation*, one can use a variety of numerical optimization techniques to find appropriate parameter estimates. The simplest technique is the method of *steepest descent* where the new parameter estimate $\\mathbf{w}^{(\\tau+1)}$ is given by\n",
    "\n",
    "$$\\mathbf{w}^{(\\tau+1)} = \\mathbf{w}^{(\\tau)} - \\eta \\bigtriangledown E(\\mathbf{w}^{(\\tau)})$$\n",
    "\n",
    "where $\\eta>0$ is the *learning rate*. Other **more advanced** optimization algorithms inlcude *conjugate gradients* and *quasi-Newton* methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogy with real neural networks\n",
    "\n",
    "Ok, well that was an awful amount of math. How do biologoical neurons do that math? We will use python list comprehensions instead of math formulas. It is easier that way!\n",
    "\n",
    "The human nervous system is composed of more than 100 billion cells known as neurons, maybe closer to 200 billion as we are born (and then neurons die when we are babies). Do you know how many stars are in a galaxy? How many galaxies in the universe? A neuron is a cell in the nervous system whose function it is to receive and transmit information. Neurons are made up of three major parts:\n",
    "\n",
    "* the cell body, or **soma**, which contains the nucleus of the cell and keeps the cell alive\n",
    "* a branching treelike fiber known as the **dendrite**, which collects information from other cells and sends the information to the soma\n",
    "* a long, segmented fiber known as the **axon**, which transmits information away from the cell body toward other neurons or to the muscles and glands\n",
    "\n",
    "<img src=\"https://c4.staticflickr.com/3/2656/4253587827_9723c3ffd3_z.jpg\" />\n",
    "\n",
    "*Photo courtesy of GE Healthcare, http://www.flickr.com/photos/gehealthcare/4253587827/ *\n",
    "\n",
    "<img src=\"https://askabiologist.asu.edu/sites/default/files/resources/articles/neuron_anatomy.jpg\"/>\n",
    "\n",
    "Some neurons have thousands of connections (dendrites), and these dendrites may themselves be branched to allow the cell to receive information from thousands of other cells. So a human brain has an order of a hundred trillion ($10^{14}$) connections.\n",
    "\n",
    "The axons are also specialized; some, such as those that send messages from the spinal cord to the muscles in the hands or feet, may be very long---even up to several feet in length. To improve the speed of their communication, and to keep their electrical charges from shorting out with other neurons, axons are often surrounded by a **myelin sheath**. The myelin sheath is a layer of fatty tissue surrounding the axon of a neuron that both acts as an insulator and allows faster transmission of the electrical signal. Axons branch out toward their ends, and at the tip of each branch is a *terminal button*.\n",
    "\n",
    "The actual working of neurons involves many aspects (including chemical, electrical, physical, timings). We abstract all of this away into three numbers:\n",
    "\n",
    "* **activation** - a value representing the excitement of a neuron\n",
    "* **default bias** - a value representing a default or bias (sometimes called a threshold)\n",
    "* **weight** - a value representing a connection to another neuron\n",
    "\n",
    "In addition, there is a **transfer function** that takes all of the incoming activations times their associated weights plus the bias, and squashes the resulting sum. This limits the activations from growing too big or too small.\n",
    "\n",
    "Time is handled in discrete steps. Real cells, of course, fire in non-discrete intervals. Consider the trigeminal ganglion cell: this is about 2 seconds of activity that was recorded from a rat ganglion cell after a single whisker (vibrissa) was moved and held in position. Listen for the rapid steady burst of action potentials. This neuron was firing about 100 action potentials every second. The picture below is the actual recording of a portion of what you are hearing...each action potential in this record is separated by about 10 milliseconds. There are 21 action potentials displayed in this picture of the recording.\n",
    "\n",
    "<img src=\"https://faculty.washington.edu/chudler/gif/spikes2.gif\" />\n",
    "\n",
    "This is what your brain sounds like on the inside. Imagine 100 billion cells doing this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(\"data/sndhair.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Networks of Neurons\n",
    "\n",
    "To build a network of neurons, we first start by grouping neurons together in **layers**.\n",
    "\n",
    "A typical Artificial Neural Network (ANN) is composed of three layers: **input**, **hidden**, and **output**. Each layer contains a collection of neurons, or simply **nodes** for short. Typically, the nodes in a layer are **fully connected** to the nodes in the next layer. For instance, every input node will have a weighted connection to every hidden node. Similarly, every hidden node will have a *weighted connection* to every output node.\n",
    "\n",
    "Processing in a network works as follows. Input is propagated forward from the input layer through the hidden layer and finally through the output layer to produce a response. Each node, regardless of the layer it is in, uses the same transfer function in order to propagate its information forward to the next layer. This is described next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node Transfer Function\n",
    "\n",
    "Each node maintains an activation value that depends on the activation values of its incoming neighbors, the weights from its incoming neighbors, and an additional value, called the **default bias value**. To compute this activation value, we first calculate the node's net input.\n",
    "\n",
    "The net input is a weighted sum of all the incoming activations plus the node's bias value:\n",
    "\n",
    "$$ net_i = \\sum\\limits_{j=1}^n w_{ij} x_j + b_i $$\n",
    "\n",
    "where $w_{ij}$ is the weight, or connection strength, from the $j^{th}$ node to the $i^{th}$ node, $x_j$ is the activation signal of the $j^{th}$ input node, and $b_i$ is the bias value of the $i^{th}$ node. \n",
    "\n",
    "Here is some corresponding Python code to compute this function for each node:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a neuron that takes in signals from 3 neurons upstream and outputs a signal to 3 neurons downstream.\n",
    "\n",
    "First, we define the indexes for the incoming nodes (`fromNodes`), and the result nodes (`toNodes`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toNodes = range(3, 5)\n",
    "fromNodes = range(0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That allows us to store the weights between nodes in a matrix, and other related values in lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias       = [0.2, -0.1, 0.5, 0.1, 0.4, 0.9]\n",
    "activation = [0.8, -0.3, -0.8, 0.1, 0.5]\n",
    "netInput   = [0, 0, 0, 0, 0]\n",
    "weights = [[ 0.1, -0.8], \n",
    "          [-0.3,  0.1], \n",
    "          [ 0.2, -0.1], \n",
    "          [ 0.0,  0.1], \n",
    "          [ 0.8, -0.8], \n",
    "          [ 0.4, 0.5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compute the `netInput[i]` as per the above equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in toNodes:\n",
    "    netInput[i] = bias[i]\n",
    "    for j in fromNodes:\n",
    "        netInput[i] += (weights[i][j] * activation[j]) \n",
    "netInput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the equivalent list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netinput_nonzero = [bias[i] + sum([weights[i][j] * activation[j] for j in fromNodes]) for i in toNodes]\n",
    "netinput_nonzero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `weights[i][j]` is the weight $w_{ij}$, or connection strength, from the $j^{th}$ node to the $i^{th}$ node, `activation[j]` is the activation signal $x_j$ of the $j^{th}$ input node, and `bias[i]` is the bias value $b_i$ of the $i^{th}$ node. \n",
    "\n",
    "After computing the net input, each node has to compute its output activation. The value that results from applying the activation function to the net input is the signal that will be sent as output to all the nodes in the next layer. The **activation function** used in backprop networks is generally:\n",
    "\n",
    "$$ a_i = \\sigma(net_i) $$\n",
    "\n",
    "where \n",
    "\n",
    "$$ \\sigma(x) = \\dfrac{1}{1 + e^{-x}} $$\n",
    "\n",
    "The method math.exp() returns returns exponential of x: $e^{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activationFunction(netInput):\n",
    "    return 1.0 / (1.0 + math.exp(-netInput))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the complete activation of a unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in toNodes:\n",
    "    activation[i] = activationFunction(netInput[i])\n",
    "activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This $\\sigma$ is the activation function, as shown in the plot below. Notice that the function is monotonically increasing and bounded by 0.0 and 1.0 as the net input approaches negative infinity and positive infinity, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "xs = range(-10, 10)\n",
    "pts = [activationFunction(x) for x in xs]\n",
    "\n",
    "plt.plot(xs, pts)\n",
    "plt.xlabel(\"input\")\n",
    "plt.ylabel(\"output\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to set the weights?\n",
    "\n",
    "For many years, it was unknown how to learn the weights in a multi-layered neural network. In addition, Marvin Minsky and Seymour Papert from MIT proved in their 1969 book [Perceptrons](https://en.wikipedia.org/wiki/Perceptrons_(book)) that you could not simulate even simple functions.\n",
    "\n",
    "Specifically, they looked at the function XOR that could not be simulated with a single layer of neurons:\n",
    "\n",
    "**Input 1** | **Input 2** | **Target**\n",
    "------------|-------------|-------\n",
    " 0 | 0 | 0\n",
    " 0 | 1 | 1 \n",
    " 1 | 0 | 1 \n",
    " 1 | 1 | 0 \n",
    "\n",
    "This killed research into neural networks for more than a decade. So, the idea of neural networks generally was ignored until the mid 1980s when the **Back-Propagation of Error** (backprop) was created. That was when [Geoffrey Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton), [Yann LeCun](https://en.wikipedia.org/wiki/Yann_LeCun) (and [here](https://yann.lecun.com)), and [Yoshua Bengio](https://en.wikipedia.org/wiki/Yoshua_Bengio) created the first successful artificial neural networks that *worked*, using many layers of neurons, from universities in Canada, because the US National Science Foundation (NSF) did not fund artificial neural network research anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Rule\n",
    "\n",
    "Backprop networks fall under the category of *supervised learning* schemes. That is, during training, the network is presented a training input, the inputs are propagated using the transfer function, until output appears in the output layer. The output is then compared with the expected or target output and an error is computed. The error is then backpropagated by applying the learning rule. \n",
    "\n",
    "A learning rule modifies the weights between nodes. The backpropagation algorithm, also called the *generalized delta rule*, systematically changes the weights by using a weight-change equation. We use an optional momentum term in the weight change rule to help speed up convergence. The weight-change rule is different for weights between the hidden-output layer nodes and the input-hidden layer nodes. For the hidden-output layer nodes it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desiredOutput = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "actualOutput = [0.8, 0.6, 0.5, 0.8, 0.3]\n",
    "\n",
    "error = [0.0 for i in desiredOutput]\n",
    "delta = [0.0 for i in desiredOutput]\n",
    "\n",
    "EPSILON = 0.1   # learning rate\n",
    "MOMENTUM = 0.01 # a smoothing term\n",
    "\n",
    "weightUpdate = [[ 0.0, 0.0], \n",
    "                [ 0.0, 0.0], \n",
    "                [ 0.0, 0.0], \n",
    "                [ 0.0, 0.0], \n",
    "                [ 0.0, 0.0], \n",
    "                [ 0.0, 0.0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the learning rule applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in toNodes:\n",
    "    error[i] = (desiredOutput[i] - actualOutput[i])\n",
    "    delta[i] = error[i] * actualOutput[i] * (1 - actualOutput[i])\n",
    "    for j in fromNodes:\n",
    "        weightUpdate[i][j] = (EPSILON * delta[i] * actualOutput[j]) + (MOMENTUM * weightUpdate[i][j])\n",
    "        \n",
    "weightUpdate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, at the $i^{th}$ output node, the error is the difference between desired and actual outputs. The weight change between a hidden layer node $j$ and output node $i$ --- `weightUpdate[i][j]` --- is a fraction of the computed delta value and additionally a fraction of the weight change from the previous training step. MOMENTUM is a constant that ranges between 0.0 and 1.0 and **EPSILON** is called the **learning rate** and is also a constant that varies between 0.0 and 1.0.\n",
    "\n",
    "In the above code `delta[i] * actualOutput[j]` is the partial derivative of the overall error with respect to each weight. This is the slope of error. Thus, backprop changes the weight a tiny portion of the slope of the error. We only know the slope of this curve, not the shape, and thus have to take very small steps.\n",
    "\n",
    "And that is all of the math, and Python, necessary to train a back-propagation of error neural network. Even though this is a very simple formulation, it has been proved that such three-layer network (input, hidden, output) is capable of computing any function that can be computed (Franklin and Garzon)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a Neural Network\n",
    "\n",
    "Given a task, how does one train a neural network to do/solve the task? This involves the following steps:\n",
    "\n",
    " 1. Determine an appropriate network architecture.\n",
    " 1. Define a data set that will be used for training.\n",
    " 1. Define the neural network parameters to be used for training.\n",
    " 1. Train the network.\n",
    " 1. Test the trained network.\n",
    " 1. Do post-training analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Determining an appropriate architecture\n",
    "\n",
    "Recall that a neural network consists of an input layer, an output layer, and zero or more hidden layers. Once a network has been trained, when you present an input to the network, the network will propagate the inputs through its layers to produce an output (using the transfer function described above). If the input represents an instance of the task, the output should be the solution to that instance after the network has been trained. Thus, one can view a neural network as a general pattern associator. Thus, given a task, the first step is to identify the nature of inputs to the pattern associator. This is normally in the form of number of nodes required to represent the input. Similarly, you will need to determine how many output nodes will be required. For example, consider a simple logical connective, AND whose input-output characteristics are summarized in the table below:\n",
    "\n",
    "**Input A** | **Input B** | **Target**\n",
    "------------|-------------|-------\n",
    " 0 | 0 | 0\n",
    " 0 | 1 | 0 \n",
    " 1 | 0 | 0 \n",
    " 1 | 1 | 1 \n",
    "\n",
    "This is a very simple example, but it will help us illustrate all of the important concepts in defining and training neural networks.\n",
    "\n",
    "In this example, it is clear that we will need two nodes in the input layer, and one in the output layer. We can start by assuming that we will not need a hidden layer. In general, as far as the design of a neural network is concerned, you always begin by identifying the size of the input and output layers. Then, you decide how many hidden layers you would use. In most situations you will need one hidden layer, though there are no hard and fast rules about its size. Through much empirical practice, you will develop your own heuristics about this. We will return to this issue later. In the case of the AND network, it is simple enough that we have decided not to use any hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define a dataset that will be used for training\n",
    "\n",
    "Once you have decided on the network architecture, you have to prepare the data set that will be used for training. Each item in the data set represents an input pattern and the correct output pattern that should be produced by the network (since this is supervised training). In most tasks, there can be an infinite number of such input-output associations. Obviously it would be impossible to enumerate all associations for all tasks (and it would make little sense to even try to do this!). You have to then decide what comprises a good representative data set that, when used in training a network, would generalize to all situations.\n",
    "\n",
    "In the case of the AND network, the data set is very small, finite (only 4 cases!), and exhaustive.\n",
    "\n",
    "The other issue you have to take into consideration here is that of the range of each input and output value. Remember the transfer function of a node is a sigmoid-function that serves to squash all input values between 0.0 and 1.0. Thus, regardless of the size of each input value into a node, the output produced by each node is between 0.0 and 1.0. This means that all output nodes have values in that range. If the task you are dealing with expects outputs between 0.0 and 1.0, then there is nothing to worry about. However, in most situations, you will need to *scale* the output values back to the values in the task domain. \n",
    "\n",
    "In reality, it is also a good idea to scale the input values from the domain into the 0.0 to 1.0 range (especially if most input values are outside the -5.0 and 5.0 range). Thus, defining a data set for training almost always requires a collection of input-output pairs, as well as scaling and unscaling operations. Luckily, for the AND task, we do not need to do any scaling, but we will see several examples of this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define the neural network parameters\n",
    "\n",
    "The next step is to define the parameters required to train the neural network. These include the following:\n",
    "\n",
    " 1. The learning constant\n",
    " 1. The momentum constant\n",
    " 1. The tolerance\n",
    " 1. Other training-related parameters\n",
    "\n",
    "The learning rate, EPSILON, and the momentum constant, MOMENTUM, have to be between 0.0 and 1.0 and are critical to the overall training algorithm. The appropriate values of these constants are best determined by experimentation. Tolerance (which is also between 0.0 and 1.0) refers to the level of tolerance that is acceptable for determining correctness of the output. For example, if tolerance is set to 0.1, then an output value within 10% of the desired output is considered correct. Other training parameters generally exist to specify the reporting rate of the progress of the training, where to log such progress, etc. We will see specific examples of these as we start working with actual networks.\n",
    "\n",
    "For the AND network, we will set EPSILON to 0.5, MOMENTUM to 0.0, report the progress every 5 epochs (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the network\n",
    "\n",
    "Once all the parameters are specified, you start the training process. This involves presenting each input pattern to the network, propagating it all the way until an output is produced, comparing the output with the desired target, computing the error, backpropagating the error, and applying the learning rule.  This process is repeated  until all inputs are exhausted. A single pass through an entire data set is called an *epoch*. In general, you always train the network for several epochs (can be anywhere from a few hundred to millions!) until the network begins to show more improved and stable performance. Performance of the network is generally measured in terms of the *total sum-squared error* or *TSS* for short. This is the error in each pattern squared and summed over all the patterns. Initially, you will notice that the TSS is quite high, but it will slowly decrease as the number of epochs increase. \n",
    "\n",
    "You can either stop the training process after a certain number of epochs have elapsed, or after the TSS has decreased to a specific amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the trained network\n",
    "\n",
    "Once the network has been trained, it is time to test it. There are several ways of doing this. Perhaps the easiest is to turn learning off (another training parameter) and then see the outputs produced by the network for each input in the data set. When a trained network is going to be used in a *deployed* application, all you have to do is save the weights of all interconnections in the network into a file. The trained network can then be recreated at anytime by reloading the weights.\n",
    "\n",
    "Note: Instead of training-then-testing, there is another methodology: you can test-while-training. Conx's neural network system supports the idea of **cross validation**. With cross validation one defines a training corpus and testing corpus at the beginning. Occasionally, as training proceeds on the training corpus, the system will stop training momentarily (by turning learning off) and test its current weights on the test corpus. This methodology has the advantage of being able to stop when performance on the test corpus begins to drop, thereby preventing over-training. See [Conx Implementation Details]() for more details on cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Do post-training analysis\n",
    "\n",
    "Perhaps the most important step in using neural networks is the analysis one performs once a network has been trained. There are a whole host of analysis techniques, we will present some of them as we go along.\n",
    "\n",
    "Next, we will use Python package `calysto` to create and experiment with neural networks. We will use the AND network example to train the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 8: The AND function\n",
    "\n",
    "Consider the AND function:\n",
    "\n",
    "**Input A** | **Input B** | **Target**\n",
    "------------|-------------|-------\n",
    " 0 | 0 | 0\n",
    " 0 | 1 | 0 \n",
    " 1 | 0 | 0 \n",
    " 1 | 1 | 1\n",
    " \n",
    " First, install the `calysto` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install calysto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the AND experiment, we will create a 2-3-1 network:\n",
    "\n",
    "* input layer consisting of two units\n",
    "* hidden layer of three (arbitrary, but not too big)\n",
    "* output layer of one unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calysto.ai.conx import *\n",
    "\n",
    "net = Network()\n",
    "net.addLayers(2, 3, 1) #input -2, hidden-3, output-1\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()\n",
    "net.addLayers(2, 3, 1)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can propagate activation through the network (from input layer, through the hidden layer, to output layer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.propagate(input=[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how an untrained network works on the AND problem, we can just propagate the input activations for each input pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pattern in [[0, 0], [0, 1], [1, 0], [1, 1]]:\n",
    "    print(pattern, net.propagate(input=pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train a network to determine the weights to compute the AND function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide training patterns (inputs and outputs)\n",
    "net.setInputs([[0.0, 0.0],[0.0, 1.0],[1.0, 0.0],[1.0, 1.0]])\n",
    "net.setOutputs([[0.0],[0.0],[0.0],[1.0]])\n",
    "\n",
    "# set learning parameters\n",
    "net.setEpsilon(0.5)\n",
    "net.setTolerance(0.2)\n",
    "net.setReportRate(1)\n",
    "\n",
    "# learn\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be pretty easy to learn this function, taking around 10 to 20 cycles through the 4 training patterns (called an **epoch**). We can test each input pattern to see if it really works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pattern in [[0, 0], [0, 1], [1, 0], [1, 1]]:\n",
    "    print(pattern, net.propagate(input=pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! It really works. But wait, it gets better.\n",
    "\n",
    "#### Generalization\n",
    "\n",
    "One of the great side benefits of using a neural network to solve a problem is that it can also do slightly different problems that it was not trained on.\n",
    "\n",
    "For example, we didn't explicitly train the network on [0.8, 0.8] for the AND problem, but we can see what the network thinks about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.propagate(input=[0.8, 0.8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a reasonable answer. To see all of the reasonable answers, we can sample the entire input space for the two input units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros((100, 100))\n",
    "\n",
    "for x in range(100):\n",
    "    for y in range(100):\n",
    "        z[x][y] = net.propagate(input=[x/100, y/100])[0]\n",
    "\n",
    "plt.imshow(z, cmap=plt.cm.gray, interpolation='nearest')\n",
    "plt.xlabel(\"input 1\")\n",
    "plt.ylabel(\"input 2\")\n",
    "plt.title(\"Output Activation\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the bottom, right-hand corner is white, meaning close to 1.0. However, the network has learned the surrounding area is a gradation between black (0.0) and white. We can describe this as **generalization**.\n",
    "\n",
    "And that's it, that's how machines learn, using just a few use cases about girlfriends, how to find the right girlfriend. And since *we are* machines, that's how we do it, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "**Your brain is mostly a predictive machine** that does math. We don't need to program machines to be human to get AI. We just need to program them just like any other program, using a bit of python, with the help of libraries like [Tensorflow](https://www.tensorflow.org/), [Torch](https://research.fb.com/downloads/torch/), etc. And we don't need to be afraid of ML. It's just statistics and linear algebra.\n",
    "\n",
    "We will now tuen our attention to packages a bit bigger than `calysto` and how to use them, culminating in `Keras`, which is the main API behind **Tensorflow 2.0**. We will also take a closer look at another ML algorithm (trees and forests) that works *great* for simpler problems and for which you do not need the power of big libraries like the ones mentionned above, and which should *always* be your first attempt at machine learning a dataset. It is often *sufficient* for the task at hand.\n",
    "\n",
    "## References\n",
    "Hinton, G. (1992) [How Neural Networks Learn From Experience](https://www.academia.edu/631731/How_neural_networks_learn_from_experience). Scientific American. September, 1992."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: \n",
    "\n",
    "### The Exclusive OR (XOR)\n",
    "\n",
    "Consider the classical Exlusive Or (XOR) [problem](https://en.wikipedia.org/wiki/Exclusive_or) involving two inputs  **x1**  and  **x2**  where  $x_i ∈ (0,1)$.\n",
    "\n",
    "This problem states that the output should be 1 if exactly one of the inputs is 1 and 0 otherwise. Thus this problem has a very simple known input-output relationship\n",
    "\n",
    "**x1** | **x2** | **Output**\n",
    "------------|-------------|-------\n",
    " 0 | 0 | 0\n",
    " 1 | 0 | 1 \n",
    " 0 | 1 | 1 \n",
    " 1 | 1 | 0\n",
    "\n",
    "The XOR network is typically presented as having 2 input nodes, 2 hidden layer nodes, and one output node.\n",
    "\n",
    "Your output layer will have a single node. You will interpret the out values as being 0 (or false) for output values less than 0 and 1 (or true) for output values greater than 0.\n",
    "\n",
    "Use `calysto` as we did for the AND to solve the Exclusive OR problem. In other words, program an [auto-encoder](https://en.wikipedia.org/wiki/Autoencoder) (generative model) for XOR.\n",
    "\n",
    "*Then*, download a dataset of your choice from the Web, and *learn it* with `calysto` (auto-encode it). Use that model to predict something useful, like how to find a girlfriend or boyfriend."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
