# Tree Based Models

Machine Learning with Tree-Based Models in Python

Learn about our new Python course. You'll learn how to use Python to train decision trees and tree-based models with the user-friendly scikit-learn machine learning library.

## Classification and Regression Trees

![](../../../res/classificationRegressionTree.png)

Classification and Regression Trees (CART) are a set of supervised learning models used for problems involving classification and regression. In this chapter, you'll be introduced to the CART algorithm.

## The Bias-Variance Tradeoff

![](../../../res/Bias-VarianceTradeoff.png)

The bias-variance tradeoff is one of the fundamental concepts in supervised machine learning. In this chapter, you'll understand how to diagnose the problems of overfitting and underfitting. You'll also be introduced to the concept of ensembling where the predictions of several models are aggregated to produce predictions that are more robust.

## Bagging and Random Forests

![](../../../res/baggin_random_forest.png)

Bagging is an ensemble method involving training the same algorithm many times using different subsets sampled from the training data. In this chapter, you'll understand how bagging can be used to create a tree ensemble. You'll also learn how the random forests algorithm can lead to further ensemble diversity through randomization at the level of each split in the trees forming the ensemble.

## Boosting

![](../../../res/Boosting_tree.png)

Boosting refers to an ensemble method in which several models are trained sequentially with each model learning from the errors of its predecessors. In this chapter, you'll be introduced to the two boosting methods of AdaBoost and Gradient Boosting.

## Model Tuning

![](../../../res/model_tuning.png)